=== ChatAnthropic Class Documentation ===
Help on class ChatAnthropic in module langchain_anthropic.chat_models:

class ChatAnthropic(langchain_core.language_models.chat_models.BaseChatModel)
 |  ChatAnthropic(*args: Any, name: Optional[str] = None, cache: Union[langchain_core.caches.BaseCache, bool, NoneType] = None, verbose: bool = <factory>, callbacks: Union[list[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[list[str]] = None, metadata: Optional[dict[str, Any]] = None, custom_get_token_ids: Optional[Callable[[str], list[int]]] = None, callback_manager: Optional[langchain_core.callbacks.base.BaseCallbackManager] = None, rate_limiter: Optional[langchain_core.rate_limiters.BaseRateLimiter] = None, disable_streaming: Union[bool, Literal['tool_calling']] = False, model_name: str, max_tokens_to_sample: int = 1024, temperature: Optional[float] = None, top_k: Optional[int] = None, top_p: Optional[float] = None, timeout: Optional[float] = None, max_retries: int = 2, stop: Optional[List[str]] = None, base_url: Optional[str] = <factory>, api_key: pydantic.types.SecretStr = <factory>, default_headers: Optional[Mapping[str, str]] = None, model_kwargs: Dict[str, Any] = <factory>, streaming: bool = False, stream_usage: bool = True) -> None
 |  
 |  Anthropic chat models.
 |  
 |  See https://docs.anthropic.com/en/docs/models-overview for a list of the latest models.
 |  
 |  Setup:
 |      Install ``langchain-anthropic`` and set environment variable ``ANTHROPIC_API_KEY``.
 |  
 |      .. code-block:: bash
 |  
 |          pip install -U langchain-anthropic
 |          export ANTHROPIC_API_KEY="your-api-key"
 |  
 |  Key init args — completion params:
 |      model: str
 |          Name of Anthropic model to use. E.g. "claude-3-sonnet-20240229".
 |      temperature: float
 |          Sampling temperature. Ranges from 0.0 to 1.0.
 |      max_tokens: int
 |          Max number of tokens to generate.
 |  
 |  Key init args — client params:
 |      timeout: Optional[float]
 |          Timeout for requests.
 |      max_retries: int
 |          Max number of retries if a request fails.
 |      api_key: Optional[str]
 |          Anthropic API key. If not passed in will be read from env var ANTHROPIC_API_KEY.
 |      base_url: Optional[str]
 |          Base URL for API requests. Only specify if using a proxy or service
 |          emulator.
 |  
 |  See full list of supported init args and their descriptions in the params section.
 |  
 |  Instantiate:
 |      .. code-block:: python
 |  
 |          from langchain_anthropic import ChatAnthropic
 |  
 |          llm = ChatAnthropic(
 |              model="claude-3-sonnet-20240229",
 |              temperature=0,
 |              max_tokens=1024,
 |              timeout=None,
 |              max_retries=2,
 |              # api_key="...",
 |              # base_url="...",
 |              # other params...
 |          )
 |  
 |  **NOTE**: Any param which is not explicitly supported will be passed directly to the
 |  ``anthropic.Anthropic.messages.create(...)`` API every time to the model is
 |  invoked. For example:
 |      .. code-block:: python
 |  
 |          from langchain_anthropic import ChatAnthropic
 |          import anthropic
 |  
 |          ChatAnthropic(..., extra_headers={}).invoke(...)
 |  
 |          # results in underlying API call of:
 |  
 |          anthropic.Anthropic(..).messages.create(..., extra_headers={})
 |  
 |          # which is also equivalent to:
 |  
 |          ChatAnthropic(...).invoke(..., extra_headers={})
 |  
 |  Invoke:
 |      .. code-block:: python
 |  
 |          messages = [
 |              ("system", "You are a helpful translator. Translate the user sentence to French."),
 |              ("human", "I love programming."),
 |          ]
 |          llm.invoke(messages)
 |  
 |      .. code-block:: python
 |  
 |          AIMessage(content="J'aime la programmation.", response_metadata={'id': 'msg_01Trik66aiQ9Z1higrD5XFx3', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 25, 'output_tokens': 11}}, id='run-5886ac5f-3c2e-49f5-8a44-b1e92808c929-0', usage_metadata={'input_tokens': 25, 'output_tokens': 11, 'total_tokens': 36})
 |  
 |  Stream:
 |      .. code-block:: python
 |  
 |          for chunk in llm.stream(messages):
 |              print(chunk)
 |  
 |      .. code-block:: python
 |  
 |          AIMessageChunk(content='J', id='run-272ff5f9-8485-402c-b90d-eac8babc5b25')
 |          AIMessageChunk(content="'", id='run-272ff5f9-8485-402c-b90d-eac8babc5b25')
 |          AIMessageChunk(content='a', id='run-272ff5f9-8485-402c-b90d-eac8babc5b25')
 |          AIMessageChunk(content='ime', id='run-272ff5f9-8485-402c-b90d-eac8babc5b25')
 |          AIMessageChunk(content=' la', id='run-272ff5f9-8485-402c-b90d-eac8babc5b25')
 |          AIMessageChunk(content=' programm', id='run-272ff5f9-8485-402c-b90d-eac8babc5b25')
 |          AIMessageChunk(content='ation', id='run-272ff5f9-8485-402c-b90d-eac8babc5b25')
 |          AIMessageChunk(content='.', id='run-272ff5f9-8485-402c-b90d-eac8babc5b25')
 |  
 |      .. code-block:: python
 |  
 |          stream = llm.stream(messages)
 |          full = next(stream)
 |          for chunk in stream:
 |              full += chunk
 |          full
 |  
 |      .. code-block:: python
 |  
 |          AIMessageChunk(content="J'aime la programmation.", id='run-b34faef0-882f-4869-a19c-ed2b856e6361')
 |  
 |  Async:
 |      .. code-block:: python
 |  
 |          await llm.ainvoke(messages)
 |  
 |          # stream:
 |          # async for chunk in (await llm.astream(messages))
 |  
 |          # batch:
 |          # await llm.abatch([messages])
 |  
 |      .. code-block:: python
 |  
 |          AIMessage(content="J'aime la programmation.", response_metadata={'id': 'msg_01Trik66aiQ9Z1higrD5XFx3', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 25, 'output_tokens': 11}}, id='run-5886ac5f-3c2e-49f5-8a44-b1e92808c929-0', usage_metadata={'input_tokens': 25, 'output_tokens': 11, 'total_tokens': 36})
 |  
 |  Tool calling:
 |      .. code-block:: python
 |  
 |          from pydantic import BaseModel, Field
 |  
 |          class GetWeather(BaseModel):
 |              '''Get the current weather in a given location'''
 |  
 |              location: str = Field(..., description="The city and state, e.g. San Francisco, CA")
 |  
 |          class GetPopulation(BaseModel):
 |              '''Get the current population in a given location'''
 |  
 |              location: str = Field(..., description="The city and state, e.g. San Francisco, CA")
 |  
 |          llm_with_tools = llm.bind_tools([GetWeather, GetPopulation])
 |          ai_msg = llm_with_tools.invoke("Which city is hotter today and which is bigger: LA or NY?")
 |          ai_msg.tool_calls
 |  
 |      .. code-block:: python
 |  
 |          [{'name': 'GetWeather',
 |            'args': {'location': 'Los Angeles, CA'},
 |            'id': 'toolu_01KzpPEAgzura7hpBqwHbWdo'},
 |           {'name': 'GetWeather',
 |            'args': {'location': 'New York, NY'},
 |            'id': 'toolu_01JtgbVGVJbiSwtZk3Uycezx'},
 |           {'name': 'GetPopulation',
 |            'args': {'location': 'Los Angeles, CA'},
 |            'id': 'toolu_01429aygngesudV9nTbCKGuw'},
 |           {'name': 'GetPopulation',
 |            'args': {'location': 'New York, NY'},
 |            'id': 'toolu_01JPktyd44tVMeBcPPnFSEJG'}]
 |  
 |      See ``ChatAnthropic.bind_tools()`` method for more.
 |  
 |  Structured output:
 |      .. code-block:: python
 |  
 |          from typing import Optional
 |  
 |          from pydantic import BaseModel, Field
 |  
 |          class Joke(BaseModel):
 |              '''Joke to tell user.'''
 |  
 |              setup: str = Field(description="The setup of the joke")
 |              punchline: str = Field(description="The punchline to the joke")
 |              rating: Optional[int] = Field(description="How funny the joke is, from 1 to 10")
 |  
 |          structured_llm = llm.with_structured_output(Joke)
 |          structured_llm.invoke("Tell me a joke about cats")
 |  
 |      .. code-block:: python
 |  
 |          Joke(setup='Why was the cat sitting on the computer?', punchline='To keep an eye on the mouse!', rating=None)
 |  
 |      See ``ChatAnthropic.with_structured_output()`` for more.
 |  
 |  Image input:
 |      .. code-block:: python
 |  
 |          import base64
 |          import httpx
 |          from langchain_core.messages import HumanMessage
 |  
 |          image_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
 |          image_data = base64.b64encode(httpx.get(image_url).content).decode("utf-8")
 |          message = HumanMessage(
 |              content=[
 |                  {"type": "text", "text": "describe the weather in this image"},
 |                  {
 |                      "type": "image_url",
 |                      "image_url": {"url": f"data:image/jpeg;base64,{image_data}"},
 |                  },
 |              ],
 |          )
 |          ai_msg = llm.invoke([message])
 |          ai_msg.content
 |  
 |      .. code-block:: python
 |  
 |          "The image depicts a sunny day with a partly cloudy sky. The sky is a brilliant blue color with scattered white clouds drifting across. The lighting and cloud patterns suggest pleasant, mild weather conditions. The scene shows a grassy field or meadow with a wooden boardwalk trail leading through it, indicating an outdoor setting on a nice day well-suited for enjoying nature."
 |  
 |  Token usage:
 |      .. code-block:: python
 |  
 |          ai_msg = llm.invoke(messages)
 |          ai_msg.usage_metadata
 |  
 |      .. code-block:: python
 |  
 |          {'input_tokens': 25, 'output_tokens': 11, 'total_tokens': 36}
 |  
 |      Message chunks containing token usage will be included during streaming by
 |      default:
 |  
 |      .. code-block:: python
 |  
 |          stream = llm.stream(messages)
 |          full = next(stream)
 |          for chunk in stream:
 |              full += chunk
 |          full.usage_metadata
 |  
 |      .. code-block:: python
 |  
 |          {'input_tokens': 25, 'output_tokens': 11, 'total_tokens': 36}
 |  
 |      These can be disabled by setting ``stream_usage=False`` in the stream method,
 |      or by setting ``stream_usage=False`` when initializing ChatAnthropic.
 |  
 |  Response metadata
 |      .. code-block:: python
 |  
 |          ai_msg = llm.invoke(messages)
 |          ai_msg.response_metadata
 |  
 |      .. code-block:: python
 |  
 |          {'id': 'msg_013xU6FHEGEq76aP4RgFerVT',
 |           'model': 'claude-3-sonnet-20240229',
 |           'stop_reason': 'end_turn',
 |           'stop_sequence': None,
 |           'usage': {'input_tokens': 25, 'output_tokens': 11}}
 |  
 |  Method resolution order:
 |      ChatAnthropic
 |      langchain_core.language_models.chat_models.BaseChatModel
 |      langchain_core.language_models.base.BaseLanguageModel[BaseMessage]
 |      langchain_core.language_models.base.BaseLanguageModel
 |      langchain_core.runnables.base.RunnableSerializable[Union[PromptValue, str, Sequence[Union[BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], ~LanguageModelOutputVar]
 |      langchain_core.runnables.base.RunnableSerializable
 |      langchain_core.load.serializable.Serializable
 |      pydantic.main.BaseModel
 |      langchain_core.runnables.base.Runnable
 |      typing.Generic
 |      abc.ABC
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  bind_tools(self, tools: Sequence[Union[Dict[str, Any], Type, Callable, langchain_core.tools.base.BaseTool]], *, tool_choice: Union[Dict[str, str], Literal['any', 'auto'], str, NoneType] = None, **kwargs: Any) -> langchain_core.runnables.base.Runnable[typing.Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[typing.Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, typing.Any]]]], langchain_core.messages.base.BaseMessage]
 |      Bind tool-like objects to this chat model.
 |      
 |      Args:
 |          tools: A list of tool definitions to bind to this chat model.
 |              Supports Anthropic format tool schemas and any tool definition handled
 |              by :meth:`~langchain_core.utils.function_calling.convert_to_openai_tool`.
 |          tool_choice: Which tool to require the model to call. Options are:
 |      
 |              - name of the tool as a string or as dict ``{"type": "tool", "name": "<<tool_name>>"}``: calls corresponding tool;
 |              - ``"auto"``, ``{"type: "auto"}``, or None: automatically selects a tool (including no tool);
 |              - ``"any"`` or ``{"type: "any"}``: force at least one tool to be called;
 |          kwargs: Any additional parameters are passed directly to
 |              :meth:`~langchain_anthropic.chat_models.ChatAnthropic.bind`.
 |      
 |      Example:
 |          .. code-block:: python
 |      
 |              from langchain_anthropic import ChatAnthropic
 |              from pydantic import BaseModel, Field
 |      
 |              class GetWeather(BaseModel):
 |                  '''Get the current weather in a given location'''
 |      
 |                  location: str = Field(..., description="The city and state, e.g. San Francisco, CA")
 |      
 |              class GetPrice(BaseModel):
 |                  '''Get the price of a specific product.'''
 |      
 |                  product: str = Field(..., description="The product to look up.")
 |      
 |      
 |              llm = ChatAnthropic(model="claude-3-5-sonnet-20240620", temperature=0)
 |              llm_with_tools = llm.bind_tools([GetWeather, GetPrice])
 |              llm_with_tools.invoke("what is the weather like in San Francisco",)
 |              # -> AIMessage(
 |              #     content=[
 |              #         {'text': '<thinking>\nBased on the user\'s question, the relevant function to call is GetWeather, which requires the "location" parameter.\n\nThe user has directly specified the location as "San Francisco". Since San Francisco is a well known city, I can reasonably infer they mean San Francisco, CA without needing the state specified.\n\nAll the required parameters are provided, so I can proceed with the API call.\n</thinking>', 'type': 'text'},
 |              #         {'text': None, 'type': 'tool_use', 'id': 'toolu_01SCgExKzQ7eqSkMHfygvYuu', 'name': 'GetWeather', 'input': {'location': 'San Francisco, CA'}}
 |              #     ],
 |              #     response_metadata={'id': 'msg_01GM3zQtoFv8jGQMW7abLnhi', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 487, 'output_tokens': 145}},
 |              #     id='run-87b1331e-9251-4a68-acef-f0a018b639cc-0'
 |              # )
 |      
 |      Example — force tool call with tool_choice 'any':
 |          .. code-block:: python
 |      
 |              from langchain_anthropic import ChatAnthropic
 |              from pydantic import BaseModel, Field
 |      
 |              class GetWeather(BaseModel):
 |                  '''Get the current weather in a given location'''
 |      
 |                  location: str = Field(..., description="The city and state, e.g. San Francisco, CA")
 |      
 |              class GetPrice(BaseModel):
 |                  '''Get the price of a specific product.'''
 |      
 |                  product: str = Field(..., description="The product to look up.")
 |      
 |      
 |              llm = ChatAnthropic(model="claude-3-5-sonnet-20240620", temperature=0)
 |              llm_with_tools = llm.bind_tools([GetWeather, GetPrice], tool_choice="any")
 |              llm_with_tools.invoke("what is the weather like in San Francisco",)
 |      
 |      
 |      Example — force specific tool call with tool_choice '<name_of_tool>':
 |          .. code-block:: python
 |      
 |              from langchain_anthropic import ChatAnthropic
 |              from pydantic import BaseModel, Field
 |      
 |              class GetWeather(BaseModel):
 |                  '''Get the current weather in a given location'''
 |      
 |                  location: str = Field(..., description="The city and state, e.g. San Francisco, CA")
 |      
 |              class GetPrice(BaseModel):
 |                  '''Get the price of a specific product.'''
 |      
 |                  product: str = Field(..., description="The product to look up.")
 |      
 |      
 |              llm = ChatAnthropic(model="claude-3-5-sonnet-20240620", temperature=0)
 |              llm_with_tools = llm.bind_tools([GetWeather, GetPrice], tool_choice="GetWeather")
 |              llm_with_tools.invoke("what is the weather like in San Francisco",)
 |      
 |      Example — cache specific tools:
 |          .. code-block:: python
 |      
 |              from langchain_anthropic import ChatAnthropic, convert_to_anthropic_tool
 |              from pydantic import BaseModel, Field
 |      
 |              class GetWeather(BaseModel):
 |                  '''Get the current weather in a given location'''
 |      
 |                  location: str = Field(..., description="The city and state, e.g. San Francisco, CA")
 |      
 |              class GetPrice(BaseModel):
 |                  '''Get the price of a specific product.'''
 |      
 |                  product: str = Field(..., description="The product to look up.")
 |      
 |              # We'll convert our pydantic class to the anthropic tool format
 |              # before passing to bind_tools so that we can set the 'cache_control'
 |              # field on our tool.
 |              cached_price_tool = convert_to_anthropic_tool(GetPrice)
 |              # Currently the only supported "cache_control" value is
 |              # {"type": "ephemeral"}.
 |              cached_price_tool["cache_control"] = {"type": "ephemeral"}
 |      
 |              # We need to pass in extra headers to enable use of the beta cache
 |              # control API.
 |              llm = ChatAnthropic(
 |                  model="claude-3-5-sonnet-20240620",
 |                  temperature=0,
 |                  extra_headers={"anthropic-beta": "prompt-caching-2024-07-31"}
 |              )
 |              llm_with_tools = llm.bind_tools([GetWeather, cached_price_tool])
 |              llm_with_tools.invoke("what is the weather like in San Francisco",)
 |      
 |          This outputs:
 |      
 |          .. code-block:: python
 |      
 |              AIMessage(content=[{'text': "Certainly! I can help you find out the current weather in San Francisco. To get this information, I'll use the GetWeather function. Let me fetch that data for you right away.", 'type': 'text'}, {'id': 'toolu_01TS5h8LNo7p5imcG7yRiaUM', 'input': {'location': 'San Francisco, CA'}, 'name': 'GetWeather', 'type': 'tool_use'}], response_metadata={'id': 'msg_01Xg7Wr5inFWgBxE5jH9rpRo', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 171, 'output_tokens': 96, 'cache_creation_input_tokens': 1470, 'cache_read_input_tokens': 0}}, id='run-b36a5b54-5d69-470e-a1b0-b932d00b089e-0', tool_calls=[{'name': 'GetWeather', 'args': {'location': 'San Francisco, CA'}, 'id': 'toolu_01TS5h8LNo7p5imcG7yRiaUM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 171, 'output_tokens': 96, 'total_tokens': 267})
 |      
 |          If we invoke the tool again, we can see that the "usage" information in the AIMessage.response_metadata shows that we had a cache hit:
 |      
 |          .. code-block:: python
 |      
 |              AIMessage(content=[{'text': 'To get the current weather in San Francisco, I can use the GetWeather function. Let me check that for you.', 'type': 'text'}, {'id': 'toolu_01HtVtY1qhMFdPprx42qU2eA', 'input': {'location': 'San Francisco, CA'}, 'name': 'GetWeather', 'type': 'tool_use'}], response_metadata={'id': 'msg_016RfWHrRvW6DAGCdwB6Ac64', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 171, 'output_tokens': 82, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 1470}}, id='run-88b1f825-dcb7-4277-ac27-53df55d22001-0', tool_calls=[{'name': 'GetWeather', 'args': {'location': 'San Francisco, CA'}, 'id': 'toolu_01HtVtY1qhMFdPprx42qU2eA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 171, 'output_tokens': 82, 'total_tokens': 253})
 |  
 |  get_num_tokens_from_messages(self, messages: List[langchain_core.messages.base.BaseMessage], tools: Optional[Sequence[Union[Dict[str, Any], Type, Callable, langchain_core.tools.base.BaseTool]]] = None) -> int
 |      .. beta::
 |         
 |      
 |      Count tokens in a sequence of input messages.
 |      
 |      Args:
 |          messages: The message inputs to tokenize.
 |          tools: If provided, sequence of dict, BaseModel, function, or BaseTools
 |              to be converted to tool schemas.
 |      
 |      Basic usage:
 |          .. code-block:: python
 |      
 |              from langchain_anthropic import ChatAnthropic
 |              from langchain_core.messages import HumanMessage, SystemMessage
 |      
 |              llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")
 |      
 |              messages = [
 |                  SystemMessage(content="You are a scientist"),
 |                  HumanMessage(content="Hello, Claude"),
 |              ]
 |              llm.get_num_tokens_from_messages(messages)
 |      
 |          .. code-block:: none
 |      
 |              14
 |      
 |      Pass tool schemas:
 |          .. code-block:: python
 |      
 |              from langchain_anthropic import ChatAnthropic
 |              from langchain_core.messages import HumanMessage
 |              from langchain_core.tools import tool
 |      
 |              llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")
 |      
 |              @tool(parse_docstring=True)
 |              def get_weather(location: str) -> str:
 |                  """Get the current weather in a given location
 |      
 |                  Args:
 |                      location: The city and state, e.g. San Francisco, CA
 |                  """
 |                  return "Sunny"
 |      
 |              messages = [
 |                  HumanMessage(content="What's the weather like in San Francisco?"),
 |              ]
 |              llm.get_num_tokens_from_messages(messages, tools=[get_weather])
 |      
 |          .. code-block:: none
 |      
 |              403
 |      
 |      .. versionchanged:: 0.3.0
 |      
 |              Uses Anthropic's token counting API to count tokens in messages. See:
 |              https://docs.anthropic.com/en/docs/build-with-claude/token-counting
 |  
 |  with_structured_output(self, schema: Union[Dict, Type[pydantic.main.BaseModel]], *, include_raw: bool = False, **kwargs: Any) -> langchain_core.runnables.base.Runnable[typing.Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[typing.Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, typing.Any]]]], typing.Union[typing.Dict, pydantic.main.BaseModel]]
 |      Model wrapper that returns outputs formatted to match the given schema.
 |      
 |      Args:
 |          schema: The output schema. Can be passed in as:
 |      
 |              - an Anthropic tool schema,
 |              - an OpenAI function/tool schema,
 |              - a JSON Schema,
 |              - a TypedDict class,
 |              - or a Pydantic class.
 |      
 |              If ``schema`` is a Pydantic class then the model output will be a
 |              Pydantic instance of that class, and the model-generated fields will be
 |              validated by the Pydantic class. Otherwise the model output will be a
 |              dict and will not be validated. See :meth:`~langchain_core.utils.function_calling.convert_to_openai_tool`
 |              for more on how to properly specify types and descriptions of
 |              schema fields when specifying a Pydantic or TypedDict class.
 |          include_raw:
 |              If False then only the parsed structured output is returned. If
 |              an error occurs during model output parsing it will be raised. If True
 |              then both the raw model response (a BaseMessage) and the parsed model
 |              response will be returned. If an error occurs during output parsing it
 |              will be caught and returned as well. The final output is always a dict
 |              with keys "raw", "parsed", and "parsing_error".
 |          kwargs: Additional keyword arguments are ignored.
 |      
 |      Returns:
 |          A Runnable that takes same inputs as a :class:`~langchain_core.language_models.chat.BaseChatModel`.
 |      
 |          If ``include_raw`` is False and ``schema`` is a Pydantic class, Runnable outputs
 |          an instance of ``schema`` (i.e., a Pydantic object).
 |      
 |          Otherwise, if ``include_raw`` is False then Runnable outputs a dict.
 |      
 |          If ``include_raw`` is True, then Runnable outputs a dict with keys:
 |              - ``"raw"``: BaseMessage
 |              - ``"parsed"``: None if there was a parsing error, otherwise the type depends on the ``schema`` as described above.
 |              - ``"parsing_error"``: Optional[BaseException]
 |      
 |      Example: Pydantic schema (include_raw=False):
 |          .. code-block:: python
 |      
 |              from langchain_anthropic import ChatAnthropic
 |              from pydantic import BaseModel
 |      
 |              class AnswerWithJustification(BaseModel):
 |                  '''An answer to the user question along with justification for the answer.'''
 |                  answer: str
 |                  justification: str
 |      
 |              llm = ChatAnthropic(model="claude-3-5-sonnet-20240620", temperature=0)
 |              structured_llm = llm.with_structured_output(AnswerWithJustification)
 |      
 |              structured_llm.invoke("What weighs more a pound of bricks or a pound of feathers")
 |      
 |              # -> AnswerWithJustification(
 |              #     answer='They weigh the same',
 |              #     justification='Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ.'
 |              # )
 |      
 |      Example:  Pydantic schema (include_raw=True):
 |          .. code-block:: python
 |      
 |              from langchain_anthropic import ChatAnthropic
 |              from pydantic import BaseModel
 |      
 |              class AnswerWithJustification(BaseModel):
 |                  '''An answer to the user question along with justification for the answer.'''
 |                  answer: str
 |                  justification: str
 |      
 |              llm = ChatAnthropic(model="claude-3-5-sonnet-20240620", temperature=0)
 |              structured_llm = llm.with_structured_output(AnswerWithJustification, include_raw=True)
 |      
 |              structured_llm.invoke("What weighs more a pound of bricks or a pound of feathers")
 |              # -> {
 |              #     'raw': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Ao02pnFYXD6GN1yzc0uXPsvF', 'function': {'arguments': '{"answer":"They weigh the same.","justification":"Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ."}', 'name': 'AnswerWithJustification'}, 'type': 'function'}]}),
 |              #     'parsed': AnswerWithJustification(answer='They weigh the same.', justification='Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ.'),
 |              #     'parsing_error': None
 |              # }
 |      
 |      Example: Dict schema (include_raw=False):
 |          .. code-block:: python
 |      
 |              from langchain_anthropic import ChatAnthropic
 |      
 |              schema = {
 |                  "name": "AnswerWithJustification",
 |                  "description": "An answer to the user question along with justification for the answer.",
 |                  "input_schema": {
 |                      "type": "object",
 |                      "properties": {
 |                          "answer": {"type": "string"},
 |                          "justification": {"type": "string"},
 |                      },
 |                      "required": ["answer", "justification"]
 |                  }
 |              }
 |              llm = ChatAnthropic(model="claude-3-5-sonnet-20240620", temperature=0)
 |              structured_llm = llm.with_structured_output(schema)
 |      
 |              structured_llm.invoke("What weighs more a pound of bricks or a pound of feathers")
 |              # -> {
 |              #     'answer': 'They weigh the same',
 |              #     'justification': 'Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume and density of the two substances differ.'
 |              # }
 |      
 |      .. versionchanged:: 0.1.22
 |      
 |              Added support for TypedDict class as `schema`.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |  
 |  build_extra(values: Dict) -> Any from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  get_lc_namespace() -> List[str] from pydantic._internal._model_construction.ModelMetaclass
 |      Get the namespace of the langchain object.
 |  
 |  is_lc_serializable() -> bool from pydantic._internal._model_construction.ModelMetaclass
 |      Is this class serializable?
 |      
 |      By design, even if a class inherits from Serializable, it is not serializable by
 |      default. This is to prevent accidental serialization of objects that should not
 |      be serialized.
 |      
 |      Returns:
 |          Whether the class is serializable. Default is False.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties defined here:
 |  
 |  lc_secrets
 |      A map of constructor argument names to secret ids.
 |      
 |      For example,
 |          {"openai_api_key": "OPENAI_API_KEY"}
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |  
 |  __abstractmethods__ = frozenset()
 |  
 |  __annotations__ = {'anthropic_api_key': <class 'pydantic.types.SecretS...
 |  
 |  __class_vars__ = set()
 |  
 |  __parameters__ = ()
 |  
 |  __private_attributes__ = {}
 |  
 |  __pydantic_complete__ = True
 |  
 |  __pydantic_computed_fields__ = {}
 |  
 |  __pydantic_core_schema__ = {'cls': <class 'langchain_anthropic.chat_mo...
 |  
 |  __pydantic_custom_init__ = True
 |  
 |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
 |  
 |  __pydantic_fields__ = {'anthropic_api_key': FieldInfo(annotation=Secre...
 |  
 |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
 |  
 |  __pydantic_parent_namespace__ = None
 |  
 |  __pydantic_post_init__ = None
 |  
 |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
 |      Model...
 |  
 |  __pydantic_validator__ = SchemaValidator(title="ChatAnthropic", valida...
 |  
 |  __signature__ = <Signature (*args: Any, name: Optional[str] = No...boo...
 |  
 |  model_config = {'arbitrary_types_allowed': True, 'extra': 'ignore', 'p...
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.language_models.chat_models.BaseChatModel:
 |  
 |  __call__(self, messages: 'list[BaseMessage]', stop: 'Optional[list[str]]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'BaseMessage'
 |      .. deprecated:: 0.1.7 Use :meth:`~invoke` instead. It will not be removed until langchain-core==1.0.
 |  
 |  async agenerate(self, messages: 'list[list[BaseMessage]]', stop: 'Optional[list[str]]' = None, callbacks: 'Callbacks' = None, *, tags: 'Optional[list[str]]' = None, metadata: 'Optional[dict[str, Any]]' = None, run_name: 'Optional[str]' = None, run_id: 'Optional[uuid.UUID]' = None, **kwargs: 'Any') -> 'LLMResult'
 |      Asynchronously pass a sequence of prompts to a model and return generations.
 |      
 |      This method should make use of batched calls for models that expose a batched
 |      API.
 |      
 |      Use this method when you want to:
 |          1. take advantage of batched calls,
 |          2. need more output from the model than just the top generated value,
 |          3. are building chains that are agnostic to the underlying language model
 |              type (e.g., pure text completion models vs chat models).
 |      
 |      Args:
 |          messages: List of list of messages.
 |          stop: Stop words to use when generating. Model output is cut off at the
 |              first occurrence of any of these substrings.
 |          callbacks: Callbacks to pass through. Used for executing additional
 |              functionality, such as logging or streaming, throughout generation.
 |          **kwargs: Arbitrary additional keyword arguments. These are usually passed
 |              to the model provider API call.
 |      
 |      Returns:
 |          An LLMResult, which contains a list of candidate Generations for each input
 |              prompt and additional model provider-specific output.
 |  
 |  async agenerate_prompt(self, prompts: 'list[PromptValue]', stop: 'Optional[list[str]]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'LLMResult'
 |      Asynchronously pass a sequence of prompts and return model generations.
 |      
 |      This method should make use of batched calls for models that expose a batched
 |      API.
 |      
 |      Use this method when you want to:
 |          1. take advantage of batched calls,
 |          2. need more output from the model than just the top generated value,
 |          3. are building chains that are agnostic to the underlying language model
 |              type (e.g., pure text completion models vs chat models).
 |      
 |      Args:
 |          prompts: List of PromptValues. A PromptValue is an object that can be
 |              converted to match the format of any language model (string for pure
 |              text generation models and BaseMessages for chat models).
 |          stop: Stop words to use when generating. Model output is cut off at the
 |              first occurrence of any of these substrings.
 |          callbacks: Callbacks to pass through. Used for executing additional
 |              functionality, such as logging or streaming, throughout generation.
 |          **kwargs: Arbitrary additional keyword arguments. These are usually passed
 |              to the model provider API call.
 |      
 |      Returns:
 |          An LLMResult, which contains a list of candidate Generations for each input
 |              prompt and additional model provider-specific output.
 |  
 |  async ainvoke(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -> 'BaseMessage'
 |      Default implementation of ainvoke, calls invoke from a thread.
 |      
 |      The default implementation allows usage of async code even if
 |      the Runnable did not implement a native async version of invoke.
 |      
 |      Subclasses should override this method if they can run asynchronously.
 |  
 |  async apredict(self, text: 'str', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'str'
 |      .. deprecated:: 0.1.7 Use :meth:`~ainvoke` instead. It will not be removed until langchain-core==1.0.
 |  
 |  async apredict_messages(self, messages: 'list[BaseMessage]', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'BaseMessage'
 |      .. deprecated:: 0.1.7 Use :meth:`~ainvoke` instead. It will not be removed until langchain-core==1.0.
 |  
 |  async astream(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -> 'AsyncIterator[BaseMessageChunk]'
 |      Default implementation of astream, which calls ainvoke.
 |      Subclasses should override this method if they support streaming output.
 |      
 |      Args:
 |          input: The input to the Runnable.
 |          config: The config to use for the Runnable. Defaults to None.
 |          kwargs: Additional keyword arguments to pass to the Runnable.
 |      
 |      Yields:
 |          The output of the Runnable.
 |  
 |  call_as_llm(self, message: 'str', stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -> 'str'
 |      .. deprecated:: 0.1.7 Use :meth:`~invoke` instead. It will not be removed until langchain-core==1.0.
 |  
 |  dict(self, **kwargs: 'Any') -> 'dict'
 |      Return a dictionary of the LLM.
 |  
 |  generate(self, messages: 'list[list[BaseMessage]]', stop: 'Optional[list[str]]' = None, callbacks: 'Callbacks' = None, *, tags: 'Optional[list[str]]' = None, metadata: 'Optional[dict[str, Any]]' = None, run_name: 'Optional[str]' = None, run_id: 'Optional[uuid.UUID]' = None, **kwargs: 'Any') -> 'LLMResult'
 |      Pass a sequence of prompts to the model and return model generations.
 |      
 |      This method should make use of batched calls for models that expose a batched
 |      API.
 |      
 |      Use this method when you want to:
 |          1. take advantage of batched calls,
 |          2. need more output from the model than just the top generated value,
 |          3. are building chains that are agnostic to the underlying language model
 |              type (e.g., pure text completion models vs chat models).
 |      
 |      Args:
 |          messages: List of list of messages.
 |          stop: Stop words to use when generating. Model output is cut off at the
 |              first occurrence of any of these substrings.
 |          callbacks: Callbacks to pass through. Used for executing additional
 |              functionality, such as logging or streaming, throughout generation.
 |          **kwargs: Arbitrary additional keyword arguments. These are usually passed
 |              to the model provider API call.
 |      
 |      Returns:
 |          An LLMResult, which contains a list of candidate Generations for each input
 |              prompt and additional model provider-specific output.
 |  
 |  generate_prompt(self, prompts: 'list[PromptValue]', stop: 'Optional[list[str]]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'LLMResult'
 |      Pass a sequence of prompts to the model and return model generations.
 |      
 |      This method should make use of batched calls for models that expose a batched
 |      API.
 |      
 |      Use this method when you want to:
 |          1. take advantage of batched calls,
 |          2. need more output from the model than just the top generated value,
 |          3. are building chains that are agnostic to the underlying language model
 |              type (e.g., pure text completion models vs chat models).
 |      
 |      Args:
 |          prompts: List of PromptValues. A PromptValue is an object that can be
 |              converted to match the format of any language model (string for pure
 |              text generation models and BaseMessages for chat models).
 |          stop: Stop words to use when generating. Model output is cut off at the
 |              first occurrence of any of these substrings.
 |          callbacks: Callbacks to pass through. Used for executing additional
 |              functionality, such as logging or streaming, throughout generation.
 |          **kwargs: Arbitrary additional keyword arguments. These are usually passed
 |              to the model provider API call.
 |      
 |      Returns:
 |          An LLMResult, which contains a list of candidate Generations for each input
 |              prompt and additional model provider-specific output.
 |  
 |  invoke(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -> 'BaseMessage'
 |      Transform a single input into an output. Override to implement.
 |      
 |      Args:
 |          input: The input to the Runnable.
 |          config: A config to use when invoking the Runnable.
 |             The config supports standard keys like 'tags', 'metadata' for tracing
 |             purposes, 'max_concurrency' for controlling how much work to do
 |             in parallel, and other keys. Please refer to the RunnableConfig
 |             for more details.
 |      
 |      Returns:
 |          The output of the Runnable.
 |  
 |  predict(self, text: 'str', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'str'
 |      .. deprecated:: 0.1.7 Use :meth:`~invoke` instead. It will not be removed until langchain-core==1.0.
 |  
 |  predict_messages(self, messages: 'list[BaseMessage]', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'BaseMessage'
 |      .. deprecated:: 0.1.7 Use :meth:`~invoke` instead. It will not be removed until langchain-core==1.0.
 |  
 |  stream(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -> 'Iterator[BaseMessageChunk]'
 |      Default implementation of stream, which calls invoke.
 |      Subclasses should override this method if they support streaming output.
 |      
 |      Args:
 |          input: The input to the Runnable.
 |          config: The config to use for the Runnable. Defaults to None.
 |          kwargs: Additional keyword arguments to pass to the Runnable.
 |      
 |      Yields:
 |          The output of the Runnable.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from langchain_core.language_models.chat_models.BaseChatModel:
 |  
 |  raise_deprecation(values: 'dict') -> 'Any' from pydantic._internal._model_construction.ModelMetaclass
 |      Raise deprecation warning if callback_manager is used.
 |      
 |      Args:
 |          values (Dict): Values to validate.
 |      
 |      Returns:
 |          Dict: Validated values.
 |      
 |      Raises:
 |          DeprecationWarning: If callback_manager is used.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from langchain_core.language_models.chat_models.BaseChatModel:
 |  
 |  OutputType
 |      Get the output type for this runnable.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.language_models.base.BaseLanguageModel:
 |  
 |  get_num_tokens(self, text: 'str') -> 'int'
 |      Get the number of tokens present in the text.
 |      
 |      Useful for checking if an input fits in a model's context window.
 |      
 |      Args:
 |          text: The string input to tokenize.
 |      
 |      Returns:
 |          The integer number of tokens in the text.
 |  
 |  get_token_ids(self, text: 'str') -> 'list[int]'
 |      Return the ordered ids of the tokens in a text.
 |      
 |      Args:
 |          text: The string input to tokenize.
 |      
 |      Returns:
 |          A list of ids corresponding to the tokens in the text, in order they occur
 |              in the text.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from langchain_core.language_models.base.BaseLanguageModel:
 |  
 |  set_verbose(verbose: 'Optional[bool]') -> 'bool' from pydantic._internal._model_construction.ModelMetaclass
 |      If verbose is None, set it.
 |      
 |      This allows users to pass in None as verbose to access the global setting.
 |      
 |      Args:
 |          verbose: The verbosity setting to use.
 |      
 |      Returns:
 |          The verbosity setting to use.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from langchain_core.language_models.base.BaseLanguageModel:
 |  
 |  InputType
 |      Get the input type for this runnable.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.runnables.base.RunnableSerializable:
 |  
 |  configurable_alternatives(self, which: 'ConfigurableField', *, default_key: 'str' = 'default', prefix_keys: 'bool' = False, **kwargs: 'Union[Runnable[Input, Output], Callable[[], Runnable[Input, Output]]]') -> 'RunnableSerializable[Input, Output]'
 |      Configure alternatives for Runnables that can be set at runtime.
 |      
 |      Args:
 |          which: The ConfigurableField instance that will be used to select the
 |              alternative.
 |          default_key: The default key to use if no alternative is selected.
 |              Defaults to "default".
 |          prefix_keys: Whether to prefix the keys with the ConfigurableField id.
 |              Defaults to False.
 |          **kwargs: A dictionary of keys to Runnable instances or callables that
 |              return Runnable instances.
 |      
 |      Returns:
 |          A new Runnable with the alternatives configured.
 |      
 |      .. code-block:: python
 |      
 |          from langchain_anthropic import ChatAnthropic
 |          from langchain_core.runnables.utils import ConfigurableField
 |          from langchain_openai import ChatOpenAI
 |      
 |          model = ChatAnthropic(
 |              model_name="claude-3-sonnet-20240229"
 |          ).configurable_alternatives(
 |              ConfigurableField(id="llm"),
 |              default_key="anthropic",
 |              openai=ChatOpenAI()
 |          )
 |      
 |          # uses the default model ChatAnthropic
 |          print(model.invoke("which organization created you?").content)
 |      
 |          # uses ChatOpenAI
 |          print(
 |              model.with_config(
 |                  configurable={"llm": "openai"}
 |              ).invoke("which organization created you?").content
 |          )
 |  
 |  configurable_fields(self, **kwargs: 'AnyConfigurableField') -> 'RunnableSerializable[Input, Output]'
 |      Configure particular Runnable fields at runtime.
 |      
 |      Args:
 |          **kwargs: A dictionary of ConfigurableField instances to configure.
 |      
 |      Returns:
 |          A new Runnable with the fields configured.
 |      
 |      .. code-block:: python
 |      
 |          from langchain_core.runnables import ConfigurableField
 |          from langchain_openai import ChatOpenAI
 |      
 |          model = ChatOpenAI(max_tokens=20).configurable_fields(
 |              max_tokens=ConfigurableField(
 |                  id="output_token_number",
 |                  name="Max tokens in the output",
 |                  description="The maximum number of tokens in the output",
 |              )
 |          )
 |      
 |          # max_tokens = 20
 |          print(
 |              "max_tokens_20: ",
 |              model.invoke("tell me something about chess").content
 |          )
 |      
 |          # max_tokens = 200
 |          print("max_tokens_200: ", model.with_config(
 |              configurable={"output_token_number": 200}
 |              ).invoke("tell me something about chess").content
 |          )
 |  
 |  to_json(self) -> 'Union[SerializedConstructor, SerializedNotImplemented]'
 |      Serialize the Runnable to JSON.
 |      
 |      Returns:
 |          A JSON-serializable representation of the Runnable.
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from langchain_core.runnables.base.RunnableSerializable:
 |  
 |  __orig_bases__ = (<class 'langchain_core.load.serializable.Serializabl...
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.load.serializable.Serializable:
 |  
 |  __init__(self, *args: Any, **kwargs: Any) -> None
 |      # Remove default BaseModel init docstring.
 |  
 |  __repr_args__(self) -> Any
 |  
 |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from langchain_core.load.serializable.Serializable:
 |  
 |  lc_id() -> list[str] from pydantic._internal._model_construction.ModelMetaclass
 |      A unique identifier for this class for serialization purposes.
 |      
 |      The unique identifier is a list of strings that describes the path
 |      to the object.
 |      For example, for the class `langchain.llms.openai.OpenAI`, the id is
 |      ["langchain", "llms", "openai", "OpenAI"].
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from langchain_core.load.serializable.Serializable:
 |  
 |  lc_attributes
 |      List of attribute names that should be included in the serialized kwargs.
 |      
 |      These attributes must be accepted by the constructor.
 |      Default is an empty dictionary.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from langchain_core.load.serializable.Serializable:
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pydantic.main.BaseModel:
 |  
 |  __copy__(self) -> 'Self'
 |      Returns a shallow copy of the model.
 |  
 |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
 |      Returns a deep copy of the model.
 |  
 |  __delattr__(self, item: 'str') -> 'Any'
 |      Implement delattr(self, name).
 |  
 |  __eq__(self, other: 'Any') -> 'bool'
 |      Return self==value.
 |  
 |  __getattr__(self, item: 'str') -> 'Any'
 |  
 |  __getstate__(self) -> 'dict[Any, Any]'
 |  
 |  __iter__(self) -> 'TupleGenerator'
 |      So `dict(model)` works.
 |  
 |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]'
 |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
 |  
 |  __replace__(self, **changes: 'Any') -> 'Self'
 |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by
 |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:
 |  
 |  __repr__(self) -> 'str'
 |      Return repr(self).
 |  
 |  __repr_name__(self) -> 'str'
 |      Name of the instance's class, used in __repr__.
 |  
 |  __repr_recursion__(self, object: 'Any') -> 'str'
 |      Returns the string representation of a recursive object.
 |  
 |  __repr_str__(self, join_str: 'str') -> 'str'
 |  
 |  __rich_repr__(self) -> 'RichReprResult'
 |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
 |  
 |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
 |      Implement setattr(self, name, value).
 |  
 |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
 |  
 |  __str__(self) -> 'str'
 |      Return str(self).
 |  
 |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Returns a copy of the model.
 |      
 |      !!! warning "Deprecated"
 |          This method is now deprecated; use `model_copy` instead.
 |      
 |      If you need `include` or `exclude`, use:
 |      
 |      ```python {test="skip" lint="skip"}
 |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
 |      data = {**data, **(update or {})}
 |      copied = self.model_validate(data)
 |      ```
 |      
 |      Args:
 |          include: Optional set or mapping specifying which fields to include in the copied model.
 |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
 |          update: Optional dictionary of field-value pairs to override field values in the copied model.
 |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
 |      
 |      Returns:
 |          A copy of the model with included, excluded and updated fields as specified.
 |  
 |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
 |  
 |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy
 |      
 |      Returns a copy of the model.
 |      
 |      Args:
 |          update: Values to change/add in the new model. Note: the data is not validated
 |              before creating the new model. You should trust this data.
 |          deep: Set to `True` to make a deep copy of the model.
 |      
 |      Returns:
 |          New model instance.
 |  
 |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump
 |      
 |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
 |      
 |      Args:
 |          mode: The mode in which `to_python` should run.
 |              If mode is 'json', the output will only contain JSON serializable types.
 |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
 |          include: A set of fields to include in the output.
 |          exclude: A set of fields to exclude from the output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to use the field's alias in the dictionary key if defined.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |      
 |      Returns:
 |          A dictionary representation of the model.
 |  
 |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json
 |      
 |      Generates a JSON representation of the model using Pydantic's `to_json` method.
 |      
 |      Args:
 |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
 |          include: Field(s) to include in the JSON output.
 |          exclude: Field(s) to exclude from the JSON output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to serialize using field aliases.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |      
 |      Returns:
 |          A JSON string representation of the model.
 |  
 |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
 |      Override this method to perform additional initialization after `__init__` and `model_construct`.
 |      This is useful if you want to do some validation that requires the entire model to be initialized.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from pydantic.main.BaseModel:
 |  
 |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema' from pydantic._internal._model_construction.ModelMetaclass
 |      Hook into generating the model's CoreSchema.
 |      
 |      Args:
 |          source: The class we are generating a schema for.
 |              This will generally be the same as the `cls` argument if this is a classmethod.
 |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
 |      
 |      Returns:
 |          A `pydantic-core` `CoreSchema`.
 |  
 |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue' from pydantic._internal._model_construction.ModelMetaclass
 |      Hook into generating the model's JSON schema.
 |      
 |      Args:
 |          core_schema: A `pydantic-core` CoreSchema.
 |              You can ignore this argument and call the handler with a new CoreSchema,
 |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
 |              or just call the handler with the original schema.
 |          handler: Call into Pydantic's internal JSON schema generation.
 |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
 |              generation fails.
 |              Since this gets called by `BaseModel.model_json_schema` you can override the
 |              `schema_generator` argument to that function to change JSON schema generation globally
 |              for a type.
 |      
 |      Returns:
 |          A JSON schema, as a Python object.
 |  
 |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass
 |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
 |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
 |      be present when this is called.
 |      
 |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
 |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
 |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
 |      
 |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
 |      any kwargs passed to the class definition that aren't used internally by pydantic.
 |      
 |      Args:
 |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
 |              by pydantic.
 |  
 |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  from_orm(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Creates a new instance of the `Model` class with validated data.
 |      
 |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
 |      Default values are respected, but no other validation is performed.
 |      
 |      !!! note
 |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
 |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
 |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
 |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
 |          an error if extra values are passed, but they will be ignored.
 |      
 |      Args:
 |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,
 |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.
 |              Otherwise, the field names from the `values` argument will be used.
 |          values: Trusted or pre-validated data dictionary.
 |      
 |      Returns:
 |          A new instance of the `Model` class with validated data.
 |  
 |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass
 |      Generates a JSON schema for a model class.
 |      
 |      Args:
 |          by_alias: Whether to use attribute aliases or not.
 |          ref_template: The reference template.
 |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
 |              `GenerateJsonSchema` with your desired modifications
 |          mode: The mode in which to generate the schema.
 |      
 |      Returns:
 |          The JSON schema for the given model class.
 |  
 |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str' from pydantic._internal._model_construction.ModelMetaclass
 |      Compute the class name for parametrizations of generic classes.
 |      
 |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
 |      
 |      Args:
 |          params: Tuple of types of the class. Given a generic class
 |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
 |              the value `(str, int)` would be passed to `params`.
 |      
 |      Returns:
 |          String representing the new class where `params` are passed to `cls` as type variables.
 |      
 |      Raises:
 |          TypeError: Raised when trying to generate concrete names for non-generic models.
 |  
 |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None' from pydantic._internal._model_construction.ModelMetaclass
 |      Try to rebuild the pydantic-core schema for the model.
 |      
 |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
 |      the initial attempt to build the schema, and automatic rebuilding fails.
 |      
 |      Args:
 |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
 |          raise_errors: Whether to raise errors, defaults to `True`.
 |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
 |          _types_namespace: The types namespace, defaults to `None`.
 |      
 |      Returns:
 |          Returns `None` if the schema is already "complete" and rebuilding was not required.
 |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
 |  
 |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Validate a pydantic model instance.
 |      
 |      Args:
 |          obj: The object to validate.
 |          strict: Whether to enforce types strictly.
 |          from_attributes: Whether to extract data from object attributes.
 |          context: Additional context to pass to the validator.
 |      
 |      Raises:
 |          ValidationError: If the object could not be validated.
 |      
 |      Returns:
 |          The validated model instance.
 |  
 |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing
 |      
 |      Validate the given JSON data against the Pydantic model.
 |      
 |      Args:
 |          json_data: The JSON data to validate.
 |          strict: Whether to enforce types strictly.
 |          context: Extra variables to pass to the validator.
 |      
 |      Returns:
 |          The validated Pydantic model.
 |      
 |      Raises:
 |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.
 |  
 |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Validate the given object with string data against the Pydantic model.
 |      
 |      Args:
 |          obj: The object containing string data to validate.
 |          strict: Whether to enforce types strictly.
 |          context: Extra variables to pass to the validator.
 |      
 |      Returns:
 |          The validated Pydantic model.
 |  
 |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  parse_obj(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  update_forward_refs(**localns: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  validate(value: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from pydantic.main.BaseModel:
 |  
 |  __fields_set__
 |  
 |  model_computed_fields
 |      Get metadata about the computed fields defined on the model.
 |      
 |      Deprecation warning: you should be getting this information from the model class, not from an instance.
 |      In V3, this property will be removed from the `BaseModel` class.
 |      
 |      Returns:
 |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.
 |  
 |  model_extra
 |      Get extra fields set during validation.
 |      
 |      Returns:
 |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
 |  
 |  model_fields
 |      Get metadata about the fields defined on the model.
 |      
 |      Deprecation warning: you should be getting this information from the model class, not from an instance.
 |      In V3, this property will be removed from the `BaseModel` class.
 |      
 |      Returns:
 |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.
 |  
 |  model_fields_set
 |      Returns the set of fields that have been explicitly set on this model instance.
 |      
 |      Returns:
 |          A set of strings representing the fields that have been set,
 |              i.e. that were not filled from defaults.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pydantic.main.BaseModel:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __pydantic_extra__
 |  
 |  __pydantic_fields_set__
 |  
 |  __pydantic_private__
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from pydantic.main.BaseModel:
 |  
 |  __hash__ = None
 |  
 |  __pydantic_root_model__ = False
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.runnables.base.Runnable:
 |  
 |  __or__(self, other: 'Union[Runnable[Any, Other], Callable[[Any], Other], Callable[[Iterator[Any]], Iterator[Other]], Mapping[str, Union[Runnable[Any, Other], Callable[[Any], Other], Any]]]') -> 'RunnableSerializable[Input, Other]'
 |      Compose this Runnable with another object to create a RunnableSequence.
 |  
 |  __ror__(self, other: 'Union[Runnable[Other, Any], Callable[[Other], Any], Callable[[Iterator[Other]], Iterator[Any]], Mapping[str, Union[Runnable[Other, Any], Callable[[Other], Any], Any]]]') -> 'RunnableSerializable[Other, Output]'
 |      Compose this Runnable with another object to create a RunnableSequence.
 |  
 |  async abatch(self, inputs: 'list[Input]', config: 'Optional[Union[RunnableConfig, list[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'list[Output]'
 |      Default implementation runs ainvoke in parallel using asyncio.gather.
 |      
 |      The default implementation of batch works well for IO bound runnables.
 |      
 |      Subclasses should override this method if they can batch more efficiently;
 |      e.g., if the underlying Runnable uses an API which supports a batch mode.
 |      
 |      Args:
 |          inputs: A list of inputs to the Runnable.
 |          config: A config to use when invoking the Runnable.
 |             The config supports standard keys like 'tags', 'metadata' for tracing
 |             purposes, 'max_concurrency' for controlling how much work to do
 |             in parallel, and other keys. Please refer to the RunnableConfig
 |             for more details. Defaults to None.
 |          return_exceptions: Whether to return exceptions instead of raising them.
 |              Defaults to False.
 |          kwargs: Additional keyword arguments to pass to the Runnable.
 |      
 |      Returns:
 |          A list of outputs from the Runnable.
 |  
 |  async abatch_as_completed(self, inputs: 'Sequence[Input]', config: 'Optional[Union[RunnableConfig, Sequence[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'AsyncIterator[tuple[int, Union[Output, Exception]]]'
 |      Run ainvoke in parallel on a list of inputs,
 |      yielding results as they complete.
 |      
 |      Args:
 |          inputs: A list of inputs to the Runnable.
 |          config: A config to use when invoking the Runnable.
 |             The config supports standard keys like 'tags', 'metadata' for tracing
 |             purposes, 'max_concurrency' for controlling how much work to do
 |             in parallel, and other keys. Please refer to the RunnableConfig
 |             for more details. Defaults to None. Defaults to None.
 |          return_exceptions: Whether to return exceptions instead of raising them.
 |              Defaults to False.
 |          kwargs: Additional keyword arguments to pass to the Runnable.
 |      
 |      Yields:
 |          A tuple of the index of the input and the output from the Runnable.
 |  
 |  as_tool(self, args_schema: 'Optional[type[BaseModel]]' = None, *, name: 'Optional[str]' = None, description: 'Optional[str]' = None, arg_types: 'Optional[dict[str, type]]' = None) -> 'BaseTool'
 |      .. beta::
 |         This API is in beta and may change in the future.
 |      
 |      Create a BaseTool from a Runnable.
 |      
 |      ``as_tool`` will instantiate a BaseTool with a name, description, and
 |      ``args_schema`` from a Runnable. Where possible, schemas are inferred
 |      from ``runnable.get_input_schema``. Alternatively (e.g., if the
 |      Runnable takes a dict as input and the specific dict keys are not typed),
 |      the schema can be specified directly with ``args_schema``. You can also
 |      pass ``arg_types`` to just specify the required arguments and their types.
 |      
 |      Args:
 |          args_schema: The schema for the tool. Defaults to None.
 |          name: The name of the tool. Defaults to None.
 |          description: The description of the tool. Defaults to None.
 |          arg_types: A dictionary of argument names to types. Defaults to None.
 |      
 |      Returns:
 |          A BaseTool instance.
 |      
 |      Typed dict input:
 |      
 |      .. code-block:: python
 |      
 |          from typing import List
 |          from typing_extensions import TypedDict
 |          from langchain_core.runnables import RunnableLambda
 |      
 |          class Args(TypedDict):
 |              a: int
 |              b: List[int]
 |      
 |          def f(x: Args) -> str:
 |              return str(x["a"] * max(x["b"]))
 |      
 |          runnable = RunnableLambda(f)
 |          as_tool = runnable.as_tool()
 |          as_tool.invoke({"a": 3, "b": [1, 2]})
 |      
 |      ``dict`` input, specifying schema via ``args_schema``:
 |      
 |      .. code-block:: python
 |      
 |          from typing import Any, Dict, List
 |          from pydantic import BaseModel, Field
 |          from langchain_core.runnables import RunnableLambda
 |      
 |          def f(x: Dict[str, Any]) -> str:
 |              return str(x["a"] * max(x["b"]))
 |      
 |          class FSchema(BaseModel):
 |              """Apply a function to an integer and list of integers."""
 |      
 |              a: int = Field(..., description="Integer")
 |              b: List[int] = Field(..., description="List of ints")
 |      
 |          runnable = RunnableLambda(f)
 |          as_tool = runnable.as_tool(FSchema)
 |          as_tool.invoke({"a": 3, "b": [1, 2]})
 |      
 |      ``dict`` input, specifying schema via ``arg_types``:
 |      
 |      .. code-block:: python
 |      
 |          from typing import Any, Dict, List
 |          from langchain_core.runnables import RunnableLambda
 |      
 |          def f(x: Dict[str, Any]) -> str:
 |              return str(x["a"] * max(x["b"]))
 |      
 |          runnable = RunnableLambda(f)
 |          as_tool = runnable.as_tool(arg_types={"a": int, "b": List[int]})
 |          as_tool.invoke({"a": 3, "b": [1, 2]})
 |      
 |      String input:
 |      
 |      .. code-block:: python
 |      
 |          from langchain_core.runnables import RunnableLambda
 |      
 |          def f(x: str) -> str:
 |              return x + "a"
 |      
 |          def g(x: str) -> str:
 |              return x + "z"
 |      
 |          runnable = RunnableLambda(f) | g
 |          as_tool = runnable.as_tool()
 |          as_tool.invoke("b")
 |      
 |      .. versionadded:: 0.2.14
 |  
 |  assign(self, **kwargs: 'Union[Runnable[dict[str, Any], Any], Callable[[dict[str, Any]], Any], Mapping[str, Union[Runnable[dict[str, Any], Any], Callable[[dict[str, Any]], Any]]]]') -> 'RunnableSerializable[Any, Any]'
 |      Assigns new fields to the dict output of this Runnable.
 |      Returns a new Runnable.
 |      
 |      .. code-block:: python
 |      
 |          from langchain_community.llms.fake import FakeStreamingListLLM
 |          from langchain_core.output_parsers import StrOutputParser
 |          from langchain_core.prompts import SystemMessagePromptTemplate
 |          from langchain_core.runnables import Runnable
 |          from operator import itemgetter
 |      
 |          prompt = (
 |              SystemMessagePromptTemplate.from_template("You are a nice assistant.")
 |              + "{question}"
 |          )
 |          llm = FakeStreamingListLLM(responses=["foo-lish"])
 |      
 |          chain: Runnable = prompt | llm | {"str": StrOutputParser()}
 |      
 |          chain_with_assign = chain.assign(hello=itemgetter("str") | llm)
 |      
 |          print(chain_with_assign.input_schema.model_json_schema())
 |          # {'title': 'PromptInput', 'type': 'object', 'properties':
 |          {'question': {'title': 'Question', 'type': 'string'}}}
 |          print(chain_with_assign.output_schema.model_json_schema())
 |          # {'title': 'RunnableSequenceOutput', 'type': 'object', 'properties':
 |          {'str': {'title': 'Str',
 |          'type': 'string'}, 'hello': {'title': 'Hello', 'type': 'string'}}}
 |  
 |  async astream_events(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, version: "Literal['v1', 'v2']", include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'AsyncIterator[StreamEvent]'
 |      Generate a stream of events.
 |      
 |      Use to create an iterator over StreamEvents that provide real-time information
 |      about the progress of the Runnable, including StreamEvents from intermediate
 |      results.
 |      
 |      A StreamEvent is a dictionary with the following schema:
 |      
 |      - ``event``: **str** - Event names are of the
 |          format: on_[runnable_type]_(start|stream|end).
 |      - ``name``: **str** - The name of the Runnable that generated the event.
 |      - ``run_id``: **str** - randomly generated ID associated with the given execution of
 |          the Runnable that emitted the event.
 |          A child Runnable that gets invoked as part of the execution of a
 |          parent Runnable is assigned its own unique ID.
 |      - ``parent_ids``: **List[str]** - The IDs of the parent runnables that
 |          generated the event. The root Runnable will have an empty list.
 |          The order of the parent IDs is from the root to the immediate parent.
 |          Only available for v2 version of the API. The v1 version of the API
 |          will return an empty list.
 |      - ``tags``: **Optional[List[str]]** - The tags of the Runnable that generated
 |          the event.
 |      - ``metadata``: **Optional[Dict[str, Any]]** - The metadata of the Runnable
 |          that generated the event.
 |      - ``data``: **Dict[str, Any]**
 |      
 |      
 |      Below is a table that illustrates some events that might be emitted by various
 |      chains. Metadata fields have been omitted from the table for brevity.
 |      Chain definitions have been included after the table.
 |      
 |      **ATTENTION** This reference table is for the V2 version of the schema.
 |      
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | event                | name             | chunk                           | input                                         | output                                          |
 |      +======================+==================+=================================+===============================================+=================================================+
 |      | on_chat_model_start  | [model name]     |                                 | {"messages": [[SystemMessage, HumanMessage]]} |                                                 |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_chat_model_stream | [model name]     | AIMessageChunk(content="hello") |                                               |                                                 |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_chat_model_end    | [model name]     |                                 | {"messages": [[SystemMessage, HumanMessage]]} | AIMessageChunk(content="hello world")           |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_llm_start         | [model name]     |                                 | {'input': 'hello'}                            |                                                 |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_llm_stream        | [model name]     | 'Hello'                         |                                               |                                                 |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_llm_end           | [model name]     |                                 | 'Hello human!'                                |                                                 |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_chain_start       | format_docs      |                                 |                                               |                                                 |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_chain_stream      | format_docs      | "hello world!, goodbye world!"  |                                               |                                                 |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_chain_end         | format_docs      |                                 | [Document(...)]                               | "hello world!, goodbye world!"                  |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_tool_start        | some_tool        |                                 | {"x": 1, "y": "2"}                            |                                                 |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_tool_end          | some_tool        |                                 |                                               | {"x": 1, "y": "2"}                              |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_retriever_start   | [retriever name] |                                 | {"query": "hello"}                            |                                                 |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_retriever_end     | [retriever name] |                                 | {"query": "hello"}                            | [Document(...), ..]                             |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_prompt_start      | [template_name]  |                                 | {"question": "hello"}                         |                                                 |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      | on_prompt_end        | [template_name]  |                                 | {"question": "hello"}                         | ChatPromptValue(messages: [SystemMessage, ...]) |
 |      +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+
 |      
 |      In addition to the standard events, users can also dispatch custom events (see example below).
 |      
 |      Custom events will be only be surfaced with in the `v2` version of the API!
 |      
 |      A custom event has following format:
 |      
 |      +-----------+------+-----------------------------------------------------------------------------------------------------------+
 |      | Attribute | Type | Description                                                                                               |
 |      +===========+======+===========================================================================================================+
 |      | name      | str  | A user defined name for the event.                                                                        |
 |      +-----------+------+-----------------------------------------------------------------------------------------------------------+
 |      | data      | Any  | The data associated with the event. This can be anything, though we suggest making it JSON serializable.  |
 |      +-----------+------+-----------------------------------------------------------------------------------------------------------+
 |      
 |      Here are declarations associated with the standard events shown above:
 |      
 |      `format_docs`:
 |      
 |      .. code-block:: python
 |      
 |          def format_docs(docs: List[Document]) -> str:
 |              '''Format the docs.'''
 |              return ", ".join([doc.page_content for doc in docs])
 |      
 |          format_docs = RunnableLambda(format_docs)
 |      
 |      `some_tool`:
 |      
 |      .. code-block:: python
 |      
 |          @tool
 |          def some_tool(x: int, y: str) -> dict:
 |              '''Some_tool.'''
 |              return {"x": x, "y": y}
 |      
 |      `prompt`:
 |      
 |      .. code-block:: python
 |      
 |          template = ChatPromptTemplate.from_messages(
 |              [("system", "You are Cat Agent 007"), ("human", "{question}")]
 |          ).with_config({"run_name": "my_template", "tags": ["my_template"]})
 |      
 |      
 |      Example:
 |      
 |      .. code-block:: python
 |      
 |          from langchain_core.runnables import RunnableLambda
 |      
 |          async def reverse(s: str) -> str:
 |              return s[::-1]
 |      
 |          chain = RunnableLambda(func=reverse)
 |      
 |          events = [
 |              event async for event in chain.astream_events("hello", version="v2")
 |          ]
 |      
 |          # will produce the following events (run_id, and parent_ids
 |          # has been omitted for brevity):
 |          [
 |              {
 |                  "data": {"input": "hello"},
 |                  "event": "on_chain_start",
 |                  "metadata": {},
 |                  "name": "reverse",
 |                  "tags": [],
 |              },
 |              {
 |                  "data": {"chunk": "olleh"},
 |                  "event": "on_chain_stream",
 |                  "metadata": {},
 |                  "name": "reverse",
 |                  "tags": [],
 |              },
 |              {
 |                  "data": {"output": "olleh"},
 |                  "event": "on_chain_end",
 |                  "metadata": {},
 |                  "name": "reverse",
 |                  "tags": [],
 |              },
 |          ]
 |      
 |      
 |      Example: Dispatch Custom Event
 |      
 |      .. code-block:: python
 |      
 |          from langchain_core.callbacks.manager import (
 |              adispatch_custom_event,
 |          )
 |          from langchain_core.runnables import RunnableLambda, RunnableConfig
 |          import asyncio
 |      
 |      
 |          async def slow_thing(some_input: str, config: RunnableConfig) -> str:
 |              """Do something that takes a long time."""
 |              await asyncio.sleep(1) # Placeholder for some slow operation
 |              await adispatch_custom_event(
 |                  "progress_event",
 |                  {"message": "Finished step 1 of 3"},
 |                  config=config # Must be included for python < 3.10
 |              )
 |              await asyncio.sleep(1) # Placeholder for some slow operation
 |              await adispatch_custom_event(
 |                  "progress_event",
 |                  {"message": "Finished step 2 of 3"},
 |                  config=config # Must be included for python < 3.10
 |              )
 |              await asyncio.sleep(1) # Placeholder for some slow operation
 |              return "Done"
 |      
 |          slow_thing = RunnableLambda(slow_thing)
 |      
 |          async for event in slow_thing.astream_events("some_input", version="v2"):
 |              print(event)
 |      
 |      Args:
 |          input: The input to the Runnable.
 |          config: The config to use for the Runnable.
 |          version: The version of the schema to use either `v2` or `v1`.
 |                   Users should use `v2`.
 |                   `v1` is for backwards compatibility and will be deprecated
 |                   in 0.4.0.
 |                   No default will be assigned until the API is stabilized.
 |                   custom events will only be surfaced in `v2`.
 |          include_names: Only include events from runnables with matching names.
 |          include_types: Only include events from runnables with matching types.
 |          include_tags: Only include events from runnables with matching tags.
 |          exclude_names: Exclude events from runnables with matching names.
 |          exclude_types: Exclude events from runnables with matching types.
 |          exclude_tags: Exclude events from runnables with matching tags.
 |          kwargs: Additional keyword arguments to pass to the Runnable.
 |              These will be passed to astream_log as this implementation
 |              of astream_events is built on top of astream_log.
 |      
 |      Yields:
 |          An async stream of StreamEvents.
 |      
 |      Raises:
 |          NotImplementedError: If the version is not `v1` or `v2`.
 |  
 |  async astream_log(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, diff: 'bool' = True, with_streamed_output_list: 'bool' = True, include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'Union[AsyncIterator[RunLogPatch], AsyncIterator[RunLog]]'
 |      Stream all output from a Runnable, as reported to the callback system.
 |      This includes all inner runs of LLMs, Retrievers, Tools, etc.
 |      
 |      Output is streamed as Log objects, which include a list of
 |      Jsonpatch ops that describe how the state of the run has changed in each
 |      step, and the final state of the run.
 |      
 |      The Jsonpatch ops can be applied in order to construct state.
 |      
 |      Args:
 |          input: The input to the Runnable.
 |          config: The config to use for the Runnable.
 |          diff: Whether to yield diffs between each step or the current state.
 |          with_streamed_output_list: Whether to yield the streamed_output list.
 |          include_names: Only include logs with these names.
 |          include_types: Only include logs with these types.
 |          include_tags: Only include logs with these tags.
 |          exclude_names: Exclude logs with these names.
 |          exclude_types: Exclude logs with these types.
 |          exclude_tags: Exclude logs with these tags.
 |          kwargs: Additional keyword arguments to pass to the Runnable.
 |      
 |      Yields:
 |          A RunLogPatch or RunLog object.
 |  
 |  async atransform(self, input: 'AsyncIterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'AsyncIterator[Output]'
 |      Default implementation of atransform, which buffers input and calls astream.
 |      Subclasses should override this method if they can start producing output while
 |      input is still being generated.
 |      
 |      Args:
 |          input: An async iterator of inputs to the Runnable.
 |          config: The config to use for the Runnable. Defaults to None.
 |          kwargs: Additional keyword arguments to pass to the Runnable.
 |      
 |      Yields:
 |          The output of the Runnable.
 |  
 |  batch(self, inputs: 'list[Input]', config: 'Optional[Union[RunnableConfig, list[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'list[Output]'
 |      Default implementation runs invoke in parallel using a thread pool executor.
 |      
 |      The default implementation of batch works well for IO bound runnables.
 |      
 |      Subclasses should override this method if they can batch more efficiently;
 |      e.g., if the underlying Runnable uses an API which supports a batch mode.
 |  
 |  batch_as_completed(self, inputs: 'Sequence[Input]', config: 'Optional[Union[RunnableConfig, Sequence[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Optional[Any]') -> 'Iterator[tuple[int, Union[Output, Exception]]]'
 |      Run invoke in parallel on a list of inputs,
 |      yielding results as they complete.
 |  
 |  bind(self, **kwargs: 'Any') -> 'Runnable[Input, Output]'
 |      Bind arguments to a Runnable, returning a new Runnable.
 |      
 |      Useful when a Runnable in a chain requires an argument that is not
 |      in the output of the previous Runnable or included in the user input.
 |      
 |      Args:
 |          kwargs: The arguments to bind to the Runnable.
 |      
 |      Returns:
 |          A new Runnable with the arguments bound.
 |      
 |      Example:
 |      
 |      .. code-block:: python
 |      
 |          from langchain_community.chat_models import ChatOllama
 |          from langchain_core.output_parsers import StrOutputParser
 |      
 |          llm = ChatOllama(model='llama2')
 |      
 |          # Without bind.
 |          chain = (
 |              llm
 |              | StrOutputParser()
 |          )
 |      
 |          chain.invoke("Repeat quoted words exactly: 'One two three four five.'")
 |          # Output is 'One two three four five.'
 |      
 |          # With bind.
 |          chain = (
 |              llm.bind(stop=["three"])
 |              | StrOutputParser()
 |          )
 |      
 |          chain.invoke("Repeat quoted words exactly: 'One two three four five.'")
 |          # Output is 'One two'
 |  
 |  config_schema(self, *, include: 'Optional[Sequence[str]]' = None) -> 'type[BaseModel]'
 |      The type of config this Runnable accepts specified as a pydantic model.
 |      
 |      To mark a field as configurable, see the `configurable_fields`
 |      and `configurable_alternatives` methods.
 |      
 |      Args:
 |          include: A list of fields to include in the config schema.
 |      
 |      Returns:
 |          A pydantic model that can be used to validate config.
 |  
 |  get_config_jsonschema(self, *, include: 'Optional[Sequence[str]]' = None) -> 'dict[str, Any]'
 |      Get a JSON schema that represents the config of the Runnable.
 |      
 |      Args:
 |          include: A list of fields to include in the config schema.
 |      
 |      Returns:
 |          A JSON schema that represents the config of the Runnable.
 |      
 |      .. versionadded:: 0.3.0
 |  
 |  get_graph(self, config: 'Optional[RunnableConfig]' = None) -> 'Graph'
 |      Return a graph representation of this Runnable.
 |  
 |  get_input_jsonschema(self, config: 'Optional[RunnableConfig]' = None) -> 'dict[str, Any]'
 |      Get a JSON schema that represents the input to the Runnable.
 |      
 |      Args:
 |          config: A config to use when generating the schema.
 |      
 |      Returns:
 |          A JSON schema that represents the input to the Runnable.
 |      
 |      Example:
 |      
 |          .. code-block:: python
 |      
 |              from langchain_core.runnables import RunnableLambda
 |      
 |              def add_one(x: int) -> int:
 |                  return x + 1
 |      
 |              runnable = RunnableLambda(add_one)
 |      
 |              print(runnable.get_input_jsonschema())
 |      
 |      .. versionadded:: 0.3.0
 |  
 |  get_input_schema(self, config: 'Optional[RunnableConfig]' = None) -> 'type[BaseModel]'
 |      Get a pydantic model that can be used to validate input to the Runnable.
 |      
 |      Runnables that leverage the configurable_fields and configurable_alternatives
 |      methods will have a dynamic input schema that depends on which
 |      configuration the Runnable is invoked with.
 |      
 |      This method allows to get an input schema for a specific configuration.
 |      
 |      Args:
 |          config: A config to use when generating the schema.
 |      
 |      Returns:
 |          A pydantic model that can be used to validate input.
 |  
 |  get_name(self, suffix: 'Optional[str]' = None, *, name: 'Optional[str]' = None) -> 'str'
 |      Get the name of the Runnable.
 |  
 |  get_output_jsonschema(self, config: 'Optional[RunnableConfig]' = None) -> 'dict[str, Any]'
 |      Get a JSON schema that represents the output of the Runnable.
 |      
 |      Args:
 |          config: A config to use when generating the schema.
 |      
 |      Returns:
 |          A JSON schema that represents the output of the Runnable.
 |      
 |      Example:
 |      
 |          .. code-block:: python
 |      
 |              from langchain_core.runnables import RunnableLambda
 |      
 |              def add_one(x: int) -> int:
 |                  return x + 1
 |      
 |              runnable = RunnableLambda(add_one)
 |      
 |              print(runnable.get_output_jsonschema())
 |      
 |      .. versionadded:: 0.3.0
 |  
 |  get_output_schema(self, config: 'Optional[RunnableConfig]' = None) -> 'type[BaseModel]'
 |      Get a pydantic model that can be used to validate output to the Runnable.
 |      
 |      Runnables that leverage the configurable_fields and configurable_alternatives
 |      methods will have a dynamic output schema that depends on which
 |      configuration the Runnable is invoked with.
 |      
 |      This method allows to get an output schema for a specific configuration.
 |      
 |      Args:
 |          config: A config to use when generating the schema.
 |      
 |      Returns:
 |          A pydantic model that can be used to validate output.
 |  
 |  get_prompts(self, config: 'Optional[RunnableConfig]' = None) -> 'list[BasePromptTemplate]'
 |      Return a list of prompts used by this Runnable.
 |  
 |  map(self) -> 'Runnable[list[Input], list[Output]]'
 |      Return a new Runnable that maps a list of inputs to a list of outputs,
 |      by calling invoke() with each input.
 |      
 |      Returns:
 |          A new Runnable that maps a list of inputs to a list of outputs.
 |      
 |      Example:
 |      
 |          .. code-block:: python
 |      
 |                  from langchain_core.runnables import RunnableLambda
 |      
 |                  def _lambda(x: int) -> int:
 |                      return x + 1
 |      
 |                  runnable = RunnableLambda(_lambda)
 |                  print(runnable.map().invoke([1, 2, 3])) # [2, 3, 4]
 |  
 |  pick(self, keys: 'Union[str, list[str]]') -> 'RunnableSerializable[Any, Any]'
 |      Pick keys from the output dict of this Runnable.
 |      
 |      Pick single key:
 |          .. code-block:: python
 |      
 |              import json
 |      
 |              from langchain_core.runnables import RunnableLambda, RunnableMap
 |      
 |              as_str = RunnableLambda(str)
 |              as_json = RunnableLambda(json.loads)
 |              chain = RunnableMap(str=as_str, json=as_json)
 |      
 |              chain.invoke("[1, 2, 3]")
 |              # -> {"str": "[1, 2, 3]", "json": [1, 2, 3]}
 |      
 |              json_only_chain = chain.pick("json")
 |              json_only_chain.invoke("[1, 2, 3]")
 |              # -> [1, 2, 3]
 |      
 |      Pick list of keys:
 |          .. code-block:: python
 |      
 |              from typing import Any
 |      
 |              import json
 |      
 |              from langchain_core.runnables import RunnableLambda, RunnableMap
 |      
 |              as_str = RunnableLambda(str)
 |              as_json = RunnableLambda(json.loads)
 |              def as_bytes(x: Any) -> bytes:
 |                  return bytes(x, "utf-8")
 |      
 |              chain = RunnableMap(
 |                  str=as_str,
 |                  json=as_json,
 |                  bytes=RunnableLambda(as_bytes)
 |              )
 |      
 |              chain.invoke("[1, 2, 3]")
 |              # -> {"str": "[1, 2, 3]", "json": [1, 2, 3], "bytes": b"[1, 2, 3]"}
 |      
 |              json_and_bytes_chain = chain.pick(["json", "bytes"])
 |              json_and_bytes_chain.invoke("[1, 2, 3]")
 |              # -> {"json": [1, 2, 3], "bytes": b"[1, 2, 3]"}
 |  
 |  pipe(self, *others: 'Union[Runnable[Any, Other], Callable[[Any], Other]]', name: 'Optional[str]' = None) -> 'RunnableSerializable[Input, Other]'
 |      Compose this Runnable with Runnable-like objects to make a RunnableSequence.
 |      
 |      Equivalent to `RunnableSequence(self, *others)` or `self | others[0] | ...`
 |      
 |      Example:
 |          .. code-block:: python
 |      
 |              from langchain_core.runnables import RunnableLambda
 |      
 |              def add_one(x: int) -> int:
 |                  return x + 1
 |      
 |              def mul_two(x: int) -> int:
 |                  return x * 2
 |      
 |              runnable_1 = RunnableLambda(add_one)
 |              runnable_2 = RunnableLambda(mul_two)
 |              sequence = runnable_1.pipe(runnable_2)
 |              # Or equivalently:
 |              # sequence = runnable_1 | runnable_2
 |              # sequence = RunnableSequence(first=runnable_1, last=runnable_2)
 |              sequence.invoke(1)
 |              await sequence.ainvoke(1)
 |              # -> 4
 |      
 |              sequence.batch([1, 2, 3])
 |              await sequence.abatch([1, 2, 3])
 |              # -> [4, 6, 8]
 |  
 |  transform(self, input: 'Iterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'Iterator[Output]'
 |      Default implementation of transform, which buffers input and then calls stream.
 |      Subclasses should override this method if they can start producing output while
 |      input is still being generated.
 |      
 |      Args:
 |          input: An iterator of inputs to the Runnable.
 |          config: The config to use for the Runnable. Defaults to None.
 |          kwargs: Additional keyword arguments to pass to the Runnable.
 |      
 |      Yields:
 |          The output of the Runnable.
 |  
 |  with_alisteners(self, *, on_start: 'Optional[AsyncListener]' = None, on_end: 'Optional[AsyncListener]' = None, on_error: 'Optional[AsyncListener]' = None) -> 'Runnable[Input, Output]'
 |      Bind asynchronous lifecycle listeners to a Runnable, returning a new Runnable.
 |      
 |      on_start: Asynchronously called before the Runnable starts running.
 |      on_end: Asynchronously called after the Runnable finishes running.
 |      on_error: Asynchronously called if the Runnable throws an error.
 |      
 |      The Run object contains information about the run, including its id,
 |      type, input, output, error, start_time, end_time, and any tags or metadata
 |      added to the run.
 |      
 |      Args:
 |          on_start: Asynchronously called before the Runnable starts running.
 |              Defaults to None.
 |          on_end: Asynchronously called after the Runnable finishes running.
 |              Defaults to None.
 |          on_error: Asynchronously called if the Runnable throws an error.
 |              Defaults to None.
 |      
 |      Returns:
 |          A new Runnable with the listeners bound.
 |      
 |      Example:
 |      
 |      .. code-block:: python
 |      
 |          from langchain_core.runnables import RunnableLambda
 |          import time
 |      
 |          async def test_runnable(time_to_sleep : int):
 |              print(f"Runnable[{time_to_sleep}s]: starts at {format_t(time.time())}")
 |              await asyncio.sleep(time_to_sleep)
 |              print(f"Runnable[{time_to_sleep}s]: ends at {format_t(time.time())}")
 |      
 |          async def fn_start(run_obj : Runnable):
 |              print(f"on start callback starts at {format_t(time.time())}
 |              await asyncio.sleep(3)
 |              print(f"on start callback ends at {format_t(time.time())}")
 |      
 |          async def fn_end(run_obj : Runnable):
 |              print(f"on end callback starts at {format_t(time.time())}
 |              await asyncio.sleep(2)
 |              print(f"on end callback ends at {format_t(time.time())}")
 |      
 |          runnable = RunnableLambda(test_runnable).with_alisteners(
 |              on_start=fn_start,
 |              on_end=fn_end
 |          )
 |          async def concurrent_runs():
 |              await asyncio.gather(runnable.ainvoke(2), runnable.ainvoke(3))
 |      
 |          asyncio.run(concurrent_runs())
 |          Result:
 |          on start callback starts at 2024-05-16T14:20:29.637053+00:00
 |          on start callback starts at 2024-05-16T14:20:29.637150+00:00
 |          on start callback ends at 2024-05-16T14:20:32.638305+00:00
 |          on start callback ends at 2024-05-16T14:20:32.638383+00:00
 |          Runnable[3s]: starts at 2024-05-16T14:20:32.638849+00:00
 |          Runnable[5s]: starts at 2024-05-16T14:20:32.638999+00:00
 |          Runnable[3s]: ends at 2024-05-16T14:20:35.640016+00:00
 |          on end callback starts at 2024-05-16T14:20:35.640534+00:00
 |          Runnable[5s]: ends at 2024-05-16T14:20:37.640169+00:00
 |          on end callback starts at 2024-05-16T14:20:37.640574+00:00
 |          on end callback ends at 2024-05-16T14:20:37.640654+00:00
 |          on end callback ends at 2024-05-16T14:20:39.641751+00:00
 |  
 |  with_config(self, config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -> 'Runnable[Input, Output]'
 |      Bind config to a Runnable, returning a new Runnable.
 |      
 |      Args:
 |          config: The config to bind to the Runnable.
 |          kwargs: Additional keyword arguments to pass to the Runnable.
 |      
 |      Returns:
 |          A new Runnable with the config bound.
 |  
 |  with_fallbacks(self, fallbacks: 'Sequence[Runnable[Input, Output]]', *, exceptions_to_handle: 'tuple[type[BaseException], ...]' = (<class 'Exception'>,), exception_key: 'Optional[str]' = None) -> 'RunnableWithFallbacksT[Input, Output]'
 |      Add fallbacks to a Runnable, returning a new Runnable.
 |      
 |      The new Runnable will try the original Runnable, and then each fallback
 |      in order, upon failures.
 |      
 |      Args:
 |          fallbacks: A sequence of runnables to try if the original Runnable fails.
 |          exceptions_to_handle: A tuple of exception types to handle.
 |              Defaults to (Exception,).
 |          exception_key: If string is specified then handled exceptions will be passed
 |              to fallbacks as part of the input under the specified key. If None,
 |              exceptions will not be passed to fallbacks. If used, the base Runnable
 |              and its fallbacks must accept a dictionary as input. Defaults to None.
 |      
 |      Returns:
 |          A new Runnable that will try the original Runnable, and then each
 |          fallback in order, upon failures.
 |      
 |      Example:
 |      
 |          .. code-block:: python
 |      
 |              from typing import Iterator
 |      
 |              from langchain_core.runnables import RunnableGenerator
 |      
 |      
 |              def _generate_immediate_error(input: Iterator) -> Iterator[str]:
 |                  raise ValueError()
 |                  yield ""
 |      
 |      
 |              def _generate(input: Iterator) -> Iterator[str]:
 |                  yield from "foo bar"
 |      
 |      
 |              runnable = RunnableGenerator(_generate_immediate_error).with_fallbacks(
 |                  [RunnableGenerator(_generate)]
 |                  )
 |              print(''.join(runnable.stream({}))) #foo bar
 |      
 |      Args:
 |          fallbacks: A sequence of runnables to try if the original Runnable fails.
 |          exceptions_to_handle: A tuple of exception types to handle.
 |          exception_key: If string is specified then handled exceptions will be passed
 |              to fallbacks as part of the input under the specified key. If None,
 |              exceptions will not be passed to fallbacks. If used, the base Runnable
 |              and its fallbacks must accept a dictionary as input.
 |      
 |      Returns:
 |          A new Runnable that will try the original Runnable, and then each
 |          fallback in order, upon failures.
 |  
 |  with_listeners(self, *, on_start: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None, on_end: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None, on_error: 'Optional[Union[Callable[[Run], None], Callable[[Run, RunnableConfig], None]]]' = None) -> 'Runnable[Input, Output]'
 |      Bind lifecycle listeners to a Runnable, returning a new Runnable.
 |      
 |      on_start: Called before the Runnable starts running, with the Run object.
 |      on_end: Called after the Runnable finishes running, with the Run object.
 |      on_error: Called if the Runnable throws an error, with the Run object.
 |      
 |      The Run object contains information about the run, including its id,
 |      type, input, output, error, start_time, end_time, and any tags or metadata
 |      added to the run.
 |      
 |      Args:
 |          on_start: Called before the Runnable starts running. Defaults to None.
 |          on_end: Called after the Runnable finishes running. Defaults to None.
 |          on_error: Called if the Runnable throws an error. Defaults to None.
 |      
 |      Returns:
 |          A new Runnable with the listeners bound.
 |      
 |      Example:
 |      
 |      .. code-block:: python
 |      
 |          from langchain_core.runnables import RunnableLambda
 |          from langchain_core.tracers.schemas import Run
 |      
 |          import time
 |      
 |          def test_runnable(time_to_sleep : int):
 |              time.sleep(time_to_sleep)
 |      
 |          def fn_start(run_obj: Run):
 |              print("start_time:", run_obj.start_time)
 |      
 |          def fn_end(run_obj: Run):
 |              print("end_time:", run_obj.end_time)
 |      
 |          chain = RunnableLambda(test_runnable).with_listeners(
 |              on_start=fn_start,
 |              on_end=fn_end
 |          )
 |          chain.invoke(2)
 |  
 |  with_retry(self, *, retry_if_exception_type: 'tuple[type[BaseException], ...]' = (<class 'Exception'>,), wait_exponential_jitter: 'bool' = True, stop_after_attempt: 'int' = 3) -> 'Runnable[Input, Output]'
 |      Create a new Runnable that retries the original Runnable on exceptions.
 |      
 |      Args:
 |          retry_if_exception_type: A tuple of exception types to retry on.
 |              Defaults to (Exception,).
 |          wait_exponential_jitter: Whether to add jitter to the wait
 |              time between retries. Defaults to True.
 |          stop_after_attempt: The maximum number of attempts to make before
 |              giving up. Defaults to 3.
 |      
 |      Returns:
 |          A new Runnable that retries the original Runnable on exceptions.
 |      
 |      Example:
 |      
 |      .. code-block:: python
 |      
 |          from langchain_core.runnables import RunnableLambda
 |      
 |          count = 0
 |      
 |      
 |          def _lambda(x: int) -> None:
 |              global count
 |              count = count + 1
 |              if x == 1:
 |                  raise ValueError("x is 1")
 |              else:
 |                   pass
 |      
 |      
 |          runnable = RunnableLambda(_lambda)
 |          try:
 |              runnable.with_retry(
 |                  stop_after_attempt=2,
 |                  retry_if_exception_type=(ValueError,),
 |              ).invoke(1)
 |          except ValueError:
 |              pass
 |      
 |          assert (count == 2)
 |      
 |      
 |      Args:
 |          retry_if_exception_type: A tuple of exception types to retry on
 |          wait_exponential_jitter: Whether to add jitter to the wait time
 |                                   between retries
 |          stop_after_attempt: The maximum number of attempts to make before giving up
 |      
 |      Returns:
 |          A new Runnable that retries the original Runnable on exceptions.
 |  
 |  with_types(self, *, input_type: 'Optional[type[Input]]' = None, output_type: 'Optional[type[Output]]' = None) -> 'Runnable[Input, Output]'
 |      Bind input and output types to a Runnable, returning a new Runnable.
 |      
 |      Args:
 |          input_type: The input type to bind to the Runnable. Defaults to None.
 |          output_type: The output type to bind to the Runnable. Defaults to None.
 |      
 |      Returns:
 |          A new Runnable with the types bound.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from langchain_core.runnables.base.Runnable:
 |  
 |  config_specs
 |      List configurable fields for this Runnable.
 |  
 |  input_schema
 |      The type of input this Runnable accepts specified as a pydantic model.
 |  
 |  output_schema
 |      The type of output this Runnable produces specified as a pydantic model.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from typing.Generic:
 |  
 |  __init_subclass__(*args, **kwargs) from pydantic._internal._model_construction.ModelMetaclass
 |      This method is called when a class is subclassed.
 |      
 |      The default implementation does nothing. It may be
 |      overridden to extend subclasses.


=== ChatAnthropic.invoke Documentation ===
Help on function invoke in module langchain_core.language_models.chat_models:

invoke(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[list[str]]' = None, **kwargs: 'Any') -> 'BaseMessage'
    Transform a single input into an output. Override to implement.
    
    Args:
        input: The input to the Runnable.
        config: A config to use when invoking the Runnable.
           The config supports standard keys like 'tags', 'metadata' for tracing
           purposes, 'max_concurrency' for controlling how much work to do
           in parallel, and other keys. Please refer to the RunnableConfig
           for more details.
    
    Returns:
        The output of the Runnable.


=== BaseMessage Documentation ===
Help on class BaseMessage in module langchain_core.messages.base:

class BaseMessage(langchain_core.load.serializable.Serializable)
 |  BaseMessage(content: 'Union[str, list[Union[str, dict]]]', *, additional_kwargs: dict = <factory>, response_metadata: dict = <factory>, type: str, name: Optional[str] = None, id: Optional[str] = None, **kwargs: Any) -> None
 |  
 |  Base abstract message class.
 |  
 |  Messages are the inputs and outputs of ChatModels.
 |  
 |  Method resolution order:
 |      BaseMessage
 |      langchain_core.load.serializable.Serializable
 |      pydantic.main.BaseModel
 |      abc.ABC
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __add__(self, other: 'Any') -> 'ChatPromptTemplate'
 |      Concatenate this message with another message.
 |  
 |  __init__(self, content: 'Union[str, list[Union[str, dict]]]', **kwargs: 'Any') -> 'None'
 |      Pass in content as positional arg.
 |      
 |      Args:
 |          content: The string contents of the message.
 |          kwargs: Additional fields to pass to the
 |  
 |  pretty_print(self) -> 'None'
 |  
 |  pretty_repr(self, html: 'bool' = False) -> 'str'
 |      Get a pretty representation of the message.
 |      
 |      Args:
 |          html: Whether to format the message as HTML. If True, the message will be
 |              formatted with HTML tags. Default is False.
 |      
 |      Returns:
 |          A pretty representation of the message.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |  
 |  cast_id_to_str(id_value: 'Any') -> 'Optional[str]' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  get_lc_namespace() -> 'list[str]' from pydantic._internal._model_construction.ModelMetaclass
 |      Get the namespace of the langchain object.
 |      Default is ["langchain", "schema", "messages"].
 |  
 |  is_lc_serializable() -> 'bool' from pydantic._internal._model_construction.ModelMetaclass
 |      Return whether this class is serializable. This is used to determine
 |      whether the class should be included in the langchain schema.
 |      
 |      Returns:
 |          True if the class is serializable, False otherwise.
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |  
 |  __abstractmethods__ = frozenset()
 |  
 |  __annotations__ = {'additional_kwargs': 'dict', 'content': 'Union[str,...
 |  
 |  __class_vars__ = set()
 |  
 |  __private_attributes__ = {}
 |  
 |  __pydantic_complete__ = True
 |  
 |  __pydantic_computed_fields__ = {}
 |  
 |  __pydantic_core_schema__ = {'cls': <class 'langchain_core.messages.bas...
 |  
 |  __pydantic_custom_init__ = True
 |  
 |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
 |  
 |  __pydantic_fields__ = {'additional_kwargs': FieldInfo(annotation=dict,...
 |  
 |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
 |  
 |  __pydantic_parent_namespace__ = None
 |  
 |  __pydantic_post_init__ = None
 |  
 |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
 |      Model...
 |  
 |  __pydantic_validator__ = SchemaValidator(title="BaseMessage", validato...
 |  
 |  __signature__ = <Signature (content: 'Union[str, list[Union[str,...id:...
 |  
 |  model_config = {'extra': 'allow'}
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.load.serializable.Serializable:
 |  
 |  __repr_args__(self) -> Any
 |  
 |  to_json(self) -> Union[langchain_core.load.serializable.SerializedConstructor, langchain_core.load.serializable.SerializedNotImplemented]
 |      Serialize the object to JSON.
 |      
 |      Returns:
 |          A json serializable object or a SerializedNotImplemented object.
 |  
 |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from langchain_core.load.serializable.Serializable:
 |  
 |  lc_id() -> list[str] from pydantic._internal._model_construction.ModelMetaclass
 |      A unique identifier for this class for serialization purposes.
 |      
 |      The unique identifier is a list of strings that describes the path
 |      to the object.
 |      For example, for the class `langchain.llms.openai.OpenAI`, the id is
 |      ["langchain", "llms", "openai", "OpenAI"].
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from langchain_core.load.serializable.Serializable:
 |  
 |  lc_attributes
 |      List of attribute names that should be included in the serialized kwargs.
 |      
 |      These attributes must be accepted by the constructor.
 |      Default is an empty dictionary.
 |  
 |  lc_secrets
 |      A map of constructor argument names to secret ids.
 |      
 |      For example,
 |          {"openai_api_key": "OPENAI_API_KEY"}
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from langchain_core.load.serializable.Serializable:
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pydantic.main.BaseModel:
 |  
 |  __copy__(self) -> 'Self'
 |      Returns a shallow copy of the model.
 |  
 |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
 |      Returns a deep copy of the model.
 |  
 |  __delattr__(self, item: 'str') -> 'Any'
 |      Implement delattr(self, name).
 |  
 |  __eq__(self, other: 'Any') -> 'bool'
 |      Return self==value.
 |  
 |  __getattr__(self, item: 'str') -> 'Any'
 |  
 |  __getstate__(self) -> 'dict[Any, Any]'
 |  
 |  __iter__(self) -> 'TupleGenerator'
 |      So `dict(model)` works.
 |  
 |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]'
 |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
 |  
 |  __replace__(self, **changes: 'Any') -> 'Self'
 |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by
 |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:
 |  
 |  __repr__(self) -> 'str'
 |      Return repr(self).
 |  
 |  __repr_name__(self) -> 'str'
 |      Name of the instance's class, used in __repr__.
 |  
 |  __repr_recursion__(self, object: 'Any') -> 'str'
 |      Returns the string representation of a recursive object.
 |  
 |  __repr_str__(self, join_str: 'str') -> 'str'
 |  
 |  __rich_repr__(self) -> 'RichReprResult'
 |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
 |  
 |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
 |      Implement setattr(self, name, value).
 |  
 |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
 |  
 |  __str__(self) -> 'str'
 |      Return str(self).
 |  
 |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Returns a copy of the model.
 |      
 |      !!! warning "Deprecated"
 |          This method is now deprecated; use `model_copy` instead.
 |      
 |      If you need `include` or `exclude`, use:
 |      
 |      ```python {test="skip" lint="skip"}
 |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
 |      data = {**data, **(update or {})}
 |      copied = self.model_validate(data)
 |      ```
 |      
 |      Args:
 |          include: Optional set or mapping specifying which fields to include in the copied model.
 |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
 |          update: Optional dictionary of field-value pairs to override field values in the copied model.
 |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
 |      
 |      Returns:
 |          A copy of the model with included, excluded and updated fields as specified.
 |  
 |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
 |  
 |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
 |  
 |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy
 |      
 |      Returns a copy of the model.
 |      
 |      Args:
 |          update: Values to change/add in the new model. Note: the data is not validated
 |              before creating the new model. You should trust this data.
 |          deep: Set to `True` to make a deep copy of the model.
 |      
 |      Returns:
 |          New model instance.
 |  
 |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump
 |      
 |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
 |      
 |      Args:
 |          mode: The mode in which `to_python` should run.
 |              If mode is 'json', the output will only contain JSON serializable types.
 |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
 |          include: A set of fields to include in the output.
 |          exclude: A set of fields to exclude from the output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to use the field's alias in the dictionary key if defined.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |      
 |      Returns:
 |          A dictionary representation of the model.
 |  
 |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json
 |      
 |      Generates a JSON representation of the model using Pydantic's `to_json` method.
 |      
 |      Args:
 |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
 |          include: Field(s) to include in the JSON output.
 |          exclude: Field(s) to exclude from the JSON output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to serialize using field aliases.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |      
 |      Returns:
 |          A JSON string representation of the model.
 |  
 |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
 |      Override this method to perform additional initialization after `__init__` and `model_construct`.
 |      This is useful if you want to do some validation that requires the entire model to be initialized.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from pydantic.main.BaseModel:
 |  
 |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema' from pydantic._internal._model_construction.ModelMetaclass
 |      Hook into generating the model's CoreSchema.
 |      
 |      Args:
 |          source: The class we are generating a schema for.
 |              This will generally be the same as the `cls` argument if this is a classmethod.
 |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
 |      
 |      Returns:
 |          A `pydantic-core` `CoreSchema`.
 |  
 |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue' from pydantic._internal._model_construction.ModelMetaclass
 |      Hook into generating the model's JSON schema.
 |      
 |      Args:
 |          core_schema: A `pydantic-core` CoreSchema.
 |              You can ignore this argument and call the handler with a new CoreSchema,
 |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
 |              or just call the handler with the original schema.
 |          handler: Call into Pydantic's internal JSON schema generation.
 |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
 |              generation fails.
 |              Since this gets called by `BaseModel.model_json_schema` you can override the
 |              `schema_generator` argument to that function to change JSON schema generation globally
 |              for a type.
 |      
 |      Returns:
 |          A JSON schema, as a Python object.
 |  
 |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass
 |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
 |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
 |      be present when this is called.
 |      
 |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
 |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
 |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
 |      
 |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
 |      any kwargs passed to the class definition that aren't used internally by pydantic.
 |      
 |      Args:
 |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
 |              by pydantic.
 |  
 |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  from_orm(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Creates a new instance of the `Model` class with validated data.
 |      
 |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
 |      Default values are respected, but no other validation is performed.
 |      
 |      !!! note
 |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
 |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
 |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
 |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
 |          an error if extra values are passed, but they will be ignored.
 |      
 |      Args:
 |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,
 |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.
 |              Otherwise, the field names from the `values` argument will be used.
 |          values: Trusted or pre-validated data dictionary.
 |      
 |      Returns:
 |          A new instance of the `Model` class with validated data.
 |  
 |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass
 |      Generates a JSON schema for a model class.
 |      
 |      Args:
 |          by_alias: Whether to use attribute aliases or not.
 |          ref_template: The reference template.
 |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
 |              `GenerateJsonSchema` with your desired modifications
 |          mode: The mode in which to generate the schema.
 |      
 |      Returns:
 |          The JSON schema for the given model class.
 |  
 |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str' from pydantic._internal._model_construction.ModelMetaclass
 |      Compute the class name for parametrizations of generic classes.
 |      
 |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
 |      
 |      Args:
 |          params: Tuple of types of the class. Given a generic class
 |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
 |              the value `(str, int)` would be passed to `params`.
 |      
 |      Returns:
 |          String representing the new class where `params` are passed to `cls` as type variables.
 |      
 |      Raises:
 |          TypeError: Raised when trying to generate concrete names for non-generic models.
 |  
 |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None' from pydantic._internal._model_construction.ModelMetaclass
 |      Try to rebuild the pydantic-core schema for the model.
 |      
 |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
 |      the initial attempt to build the schema, and automatic rebuilding fails.
 |      
 |      Args:
 |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
 |          raise_errors: Whether to raise errors, defaults to `True`.
 |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
 |          _types_namespace: The types namespace, defaults to `None`.
 |      
 |      Returns:
 |          Returns `None` if the schema is already "complete" and rebuilding was not required.
 |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
 |  
 |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Validate a pydantic model instance.
 |      
 |      Args:
 |          obj: The object to validate.
 |          strict: Whether to enforce types strictly.
 |          from_attributes: Whether to extract data from object attributes.
 |          context: Additional context to pass to the validator.
 |      
 |      Raises:
 |          ValidationError: If the object could not be validated.
 |      
 |      Returns:
 |          The validated model instance.
 |  
 |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing
 |      
 |      Validate the given JSON data against the Pydantic model.
 |      
 |      Args:
 |          json_data: The JSON data to validate.
 |          strict: Whether to enforce types strictly.
 |          context: Extra variables to pass to the validator.
 |      
 |      Returns:
 |          The validated Pydantic model.
 |      
 |      Raises:
 |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.
 |  
 |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Validate the given object with string data against the Pydantic model.
 |      
 |      Args:
 |          obj: The object containing string data to validate.
 |          strict: Whether to enforce types strictly.
 |          context: Extra variables to pass to the validator.
 |      
 |      Returns:
 |          The validated Pydantic model.
 |  
 |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  parse_obj(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  update_forward_refs(**localns: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  validate(value: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from pydantic.main.BaseModel:
 |  
 |  __fields_set__
 |  
 |  model_computed_fields
 |      Get metadata about the computed fields defined on the model.
 |      
 |      Deprecation warning: you should be getting this information from the model class, not from an instance.
 |      In V3, this property will be removed from the `BaseModel` class.
 |      
 |      Returns:
 |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.
 |  
 |  model_extra
 |      Get extra fields set during validation.
 |      
 |      Returns:
 |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
 |  
 |  model_fields
 |      Get metadata about the fields defined on the model.
 |      
 |      Deprecation warning: you should be getting this information from the model class, not from an instance.
 |      In V3, this property will be removed from the `BaseModel` class.
 |      
 |      Returns:
 |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.
 |  
 |  model_fields_set
 |      Returns the set of fields that have been explicitly set on this model instance.
 |      
 |      Returns:
 |          A set of strings representing the fields that have been set,
 |              i.e. that were not filled from defaults.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pydantic.main.BaseModel:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __pydantic_extra__
 |  
 |  __pydantic_fields_set__
 |  
 |  __pydantic_private__
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from pydantic.main.BaseModel:
 |  
 |  __hash__ = None
 |  
 |  __pydantic_root_model__ = False


=== DynamoDBChatMessageHistory Documentation ===
Help on class DynamoDBChatMessageHistory in module langchain_community.chat_message_histories.dynamodb:

class DynamoDBChatMessageHistory(langchain_core.chat_history.BaseChatMessageHistory)
 |  DynamoDBChatMessageHistory(table_name: 'str', session_id: 'str', endpoint_url: 'Optional[str]' = None, primary_key_name: 'str' = 'SessionId', key: 'Optional[Dict[str, str]]' = None, boto3_session: 'Optional[Session]' = None, kms_key_id: 'Optional[str]' = None, ttl: 'Optional[int]' = None, ttl_key_name: 'str' = 'expireAt', history_size: 'Optional[int]' = None, history_messages_key: 'Optional[str]' = 'History', *, coerce_float_to_decimal: 'bool' = False)
 |  
 |  Chat message history that stores history in AWS DynamoDB.
 |  
 |  This class expects that a DynamoDB table exists with name `table_name`
 |  
 |  Args:
 |      table_name: name of the DynamoDB table
 |      session_id: arbitrary key that is used to store the messages
 |          of a single chat session.
 |      endpoint_url: URL of the AWS endpoint to connect to. This argument
 |          is optional and useful for test purposes, like using Localstack.
 |          If you plan to use AWS cloud service, you normally don't have to
 |          worry about setting the endpoint_url.
 |      primary_key_name: name of the primary key of the DynamoDB table. This argument
 |          is optional, defaulting to "SessionId".
 |      key: an optional dictionary with a custom primary and secondary key.
 |          This argument is optional, but useful when using composite dynamodb keys, or
 |          isolating records based off of application details such as a user id.
 |          This may also contain global and local secondary index keys.
 |      kms_key_id: an optional AWS KMS Key ID, AWS KMS Key ARN, or AWS KMS Alias for
 |          client-side encryption
 |      ttl: Optional Time-to-live (TTL) in seconds. Allows you to define a per-item
 |          expiration timestamp that indicates when an item can be deleted from the
 |          table. DynamoDB handles deletion of expired items without consuming
 |          write throughput. To enable this feature on the table, follow the
 |          [AWS DynamoDB documentation](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/time-to-live-ttl-how-to.html)
 |      history_size: Maximum number of messages to store. If None then there is no
 |          limit. If not None then only the latest `history_size` messages are stored.
 |      history_messages_key: Key for the chat history where the messages
 |          are stored and updated
 |      coerce_float_to_decimal: If True, all float values in the messages will be
 |          converted to Decimal.
 |  
 |  Method resolution order:
 |      DynamoDBChatMessageHistory
 |      langchain_core.chat_history.BaseChatMessageHistory
 |      abc.ABC
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, table_name: 'str', session_id: 'str', endpoint_url: 'Optional[str]' = None, primary_key_name: 'str' = 'SessionId', key: 'Optional[Dict[str, str]]' = None, boto3_session: 'Optional[Session]' = None, kms_key_id: 'Optional[str]' = None, ttl: 'Optional[int]' = None, ttl_key_name: 'str' = 'expireAt', history_size: 'Optional[int]' = None, history_messages_key: 'Optional[str]' = 'History', *, coerce_float_to_decimal: 'bool' = False)
 |      Initialize self.  See help(type(self)) for accurate signature.
 |  
 |  add_message(self, message: 'BaseMessage') -> 'None'
 |      Append the message to the record in DynamoDB
 |  
 |  clear(self) -> 'None'
 |      Clear session memory from DynamoDB
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |  
 |  messages
 |      Retrieve the messages from DynamoDB
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |  
 |  __abstractmethods__ = frozenset()
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.chat_history.BaseChatMessageHistory:
 |  
 |  __str__(self) -> 'str'
 |      Return a string representation of the chat history.
 |  
 |  async aadd_messages(self, messages: 'Sequence[BaseMessage]') -> 'None'
 |      Async add a list of messages.
 |      
 |      Args:
 |          messages: A sequence of BaseMessage objects to store.
 |  
 |  async aclear(self) -> 'None'
 |      Async remove all messages from the store
 |  
 |  add_ai_message(self, message: 'Union[AIMessage, str]') -> 'None'
 |      Convenience method for adding an AI message string to the store.
 |      
 |      Please note that this is a convenience method. Code should favor the bulk
 |      add_messages interface instead to save on round-trips to the underlying
 |      persistence layer.
 |      
 |      This method may be deprecated in a future release.
 |      
 |      Args:
 |          message: The AI message to add.
 |  
 |  add_messages(self, messages: 'Sequence[BaseMessage]') -> 'None'
 |      Add a list of messages.
 |      
 |      Implementations should over-ride this method to handle bulk addition of messages
 |      in an efficient manner to avoid unnecessary round-trips to the underlying store.
 |      
 |      Args:
 |          messages: A sequence of BaseMessage objects to store.
 |  
 |  add_user_message(self, message: 'Union[HumanMessage, str]') -> 'None'
 |      Convenience method for adding a human message string to the store.
 |      
 |      Please note that this is a convenience method. Code should favor the
 |      bulk add_messages interface instead to save on round-trips to the underlying
 |      persistence layer.
 |      
 |      This method may be deprecated in a future release.
 |      
 |      Args:
 |          message: The human message to add to the store.
 |  
 |  async aget_messages(self) -> 'list[BaseMessage]'
 |      Async version of getting messages.
 |      
 |      Can over-ride this method to provide an efficient async implementation.
 |      
 |      In general, fetching messages may involve IO to the underlying
 |      persistence layer.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from langchain_core.chat_history.BaseChatMessageHistory:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from langchain_core.chat_history.BaseChatMessageHistory:
 |  
 |  __annotations__ = {'messages': 'list[BaseMessage]'}


=== SystemMessage Documentation ===
Help on class SystemMessage in module langchain_core.messages.system:

class SystemMessage(langchain_core.messages.base.BaseMessage)
 |  SystemMessage(content: Union[str, list[Union[str, dict]]], *, additional_kwargs: dict = <factory>, response_metadata: dict = <factory>, type: Literal['system'] = 'system', name: Optional[str] = None, id: Optional[str] = None, **kwargs: Any) -> None
 |  
 |  Message for priming AI behavior.
 |  
 |  The system message is usually passed in as the first of a sequence
 |  of input messages.
 |  
 |  Example:
 |  
 |      .. code-block:: python
 |  
 |          from langchain_core.messages import HumanMessage, SystemMessage
 |  
 |          messages = [
 |              SystemMessage(
 |                  content="You are a helpful assistant! Your name is Bob."
 |              ),
 |              HumanMessage(
 |                  content="What is your name?"
 |              )
 |          ]
 |  
 |          # Define a chat model and invoke it with the messages
 |          print(model.invoke(messages))
 |  
 |  Method resolution order:
 |      SystemMessage
 |      langchain_core.messages.base.BaseMessage
 |      langchain_core.load.serializable.Serializable
 |      pydantic.main.BaseModel
 |      abc.ABC
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, content: Union[str, list[Union[str, dict]]], **kwargs: Any) -> None
 |      Pass in content as positional arg.
 |      
 |      Args:
 |             content: The string contents of the message.
 |             kwargs: Additional fields to pass to the message.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |  
 |  get_lc_namespace() -> list[str] from pydantic._internal._model_construction.ModelMetaclass
 |      Get the namespace of the langchain object.
 |      Default is ["langchain", "schema", "messages"].
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |  
 |  __abstractmethods__ = frozenset()
 |  
 |  __annotations__ = {'type': typing.Literal['system']}
 |  
 |  __class_vars__ = set()
 |  
 |  __private_attributes__ = {}
 |  
 |  __pydantic_complete__ = True
 |  
 |  __pydantic_computed_fields__ = {}
 |  
 |  __pydantic_core_schema__ = {'cls': <class 'langchain_core.messages.sys...
 |  
 |  __pydantic_custom_init__ = True
 |  
 |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
 |  
 |  __pydantic_fields__ = {'additional_kwargs': FieldInfo(annotation=dict,...
 |  
 |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
 |  
 |  __pydantic_parent_namespace__ = None
 |  
 |  __pydantic_post_init__ = None
 |  
 |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
 |      Model...
 |  
 |  __pydantic_validator__ = SchemaValidator(title="SystemMessage", valida...
 |  
 |  __signature__ = <Signature (content: Union[str, list[Union[str, ...id:...
 |  
 |  model_config = {'extra': 'allow'}
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.messages.base.BaseMessage:
 |  
 |  __add__(self, other: 'Any') -> 'ChatPromptTemplate'
 |      Concatenate this message with another message.
 |  
 |  pretty_print(self) -> 'None'
 |  
 |  pretty_repr(self, html: 'bool' = False) -> 'str'
 |      Get a pretty representation of the message.
 |      
 |      Args:
 |          html: Whether to format the message as HTML. If True, the message will be
 |              formatted with HTML tags. Default is False.
 |      
 |      Returns:
 |          A pretty representation of the message.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from langchain_core.messages.base.BaseMessage:
 |  
 |  cast_id_to_str(id_value: 'Any') -> 'Optional[str]' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  is_lc_serializable() -> 'bool' from pydantic._internal._model_construction.ModelMetaclass
 |      Return whether this class is serializable. This is used to determine
 |      whether the class should be included in the langchain schema.
 |      
 |      Returns:
 |          True if the class is serializable, False otherwise.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.load.serializable.Serializable:
 |  
 |  __repr_args__(self) -> Any
 |  
 |  to_json(self) -> Union[langchain_core.load.serializable.SerializedConstructor, langchain_core.load.serializable.SerializedNotImplemented]
 |      Serialize the object to JSON.
 |      
 |      Returns:
 |          A json serializable object or a SerializedNotImplemented object.
 |  
 |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from langchain_core.load.serializable.Serializable:
 |  
 |  lc_id() -> list[str] from pydantic._internal._model_construction.ModelMetaclass
 |      A unique identifier for this class for serialization purposes.
 |      
 |      The unique identifier is a list of strings that describes the path
 |      to the object.
 |      For example, for the class `langchain.llms.openai.OpenAI`, the id is
 |      ["langchain", "llms", "openai", "OpenAI"].
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from langchain_core.load.serializable.Serializable:
 |  
 |  lc_attributes
 |      List of attribute names that should be included in the serialized kwargs.
 |      
 |      These attributes must be accepted by the constructor.
 |      Default is an empty dictionary.
 |  
 |  lc_secrets
 |      A map of constructor argument names to secret ids.
 |      
 |      For example,
 |          {"openai_api_key": "OPENAI_API_KEY"}
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from langchain_core.load.serializable.Serializable:
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pydantic.main.BaseModel:
 |  
 |  __copy__(self) -> 'Self'
 |      Returns a shallow copy of the model.
 |  
 |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
 |      Returns a deep copy of the model.
 |  
 |  __delattr__(self, item: 'str') -> 'Any'
 |      Implement delattr(self, name).
 |  
 |  __eq__(self, other: 'Any') -> 'bool'
 |      Return self==value.
 |  
 |  __getattr__(self, item: 'str') -> 'Any'
 |  
 |  __getstate__(self) -> 'dict[Any, Any]'
 |  
 |  __iter__(self) -> 'TupleGenerator'
 |      So `dict(model)` works.
 |  
 |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]'
 |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
 |  
 |  __replace__(self, **changes: 'Any') -> 'Self'
 |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by
 |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:
 |  
 |  __repr__(self) -> 'str'
 |      Return repr(self).
 |  
 |  __repr_name__(self) -> 'str'
 |      Name of the instance's class, used in __repr__.
 |  
 |  __repr_recursion__(self, object: 'Any') -> 'str'
 |      Returns the string representation of a recursive object.
 |  
 |  __repr_str__(self, join_str: 'str') -> 'str'
 |  
 |  __rich_repr__(self) -> 'RichReprResult'
 |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
 |  
 |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
 |      Implement setattr(self, name, value).
 |  
 |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
 |  
 |  __str__(self) -> 'str'
 |      Return str(self).
 |  
 |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Returns a copy of the model.
 |      
 |      !!! warning "Deprecated"
 |          This method is now deprecated; use `model_copy` instead.
 |      
 |      If you need `include` or `exclude`, use:
 |      
 |      ```python {test="skip" lint="skip"}
 |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
 |      data = {**data, **(update or {})}
 |      copied = self.model_validate(data)
 |      ```
 |      
 |      Args:
 |          include: Optional set or mapping specifying which fields to include in the copied model.
 |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
 |          update: Optional dictionary of field-value pairs to override field values in the copied model.
 |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
 |      
 |      Returns:
 |          A copy of the model with included, excluded and updated fields as specified.
 |  
 |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
 |  
 |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
 |  
 |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy
 |      
 |      Returns a copy of the model.
 |      
 |      Args:
 |          update: Values to change/add in the new model. Note: the data is not validated
 |              before creating the new model. You should trust this data.
 |          deep: Set to `True` to make a deep copy of the model.
 |      
 |      Returns:
 |          New model instance.
 |  
 |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump
 |      
 |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
 |      
 |      Args:
 |          mode: The mode in which `to_python` should run.
 |              If mode is 'json', the output will only contain JSON serializable types.
 |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
 |          include: A set of fields to include in the output.
 |          exclude: A set of fields to exclude from the output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to use the field's alias in the dictionary key if defined.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |      
 |      Returns:
 |          A dictionary representation of the model.
 |  
 |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json
 |      
 |      Generates a JSON representation of the model using Pydantic's `to_json` method.
 |      
 |      Args:
 |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
 |          include: Field(s) to include in the JSON output.
 |          exclude: Field(s) to exclude from the JSON output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to serialize using field aliases.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |      
 |      Returns:
 |          A JSON string representation of the model.
 |  
 |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
 |      Override this method to perform additional initialization after `__init__` and `model_construct`.
 |      This is useful if you want to do some validation that requires the entire model to be initialized.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from pydantic.main.BaseModel:
 |  
 |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema' from pydantic._internal._model_construction.ModelMetaclass
 |      Hook into generating the model's CoreSchema.
 |      
 |      Args:
 |          source: The class we are generating a schema for.
 |              This will generally be the same as the `cls` argument if this is a classmethod.
 |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
 |      
 |      Returns:
 |          A `pydantic-core` `CoreSchema`.
 |  
 |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue' from pydantic._internal._model_construction.ModelMetaclass
 |      Hook into generating the model's JSON schema.
 |      
 |      Args:
 |          core_schema: A `pydantic-core` CoreSchema.
 |              You can ignore this argument and call the handler with a new CoreSchema,
 |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
 |              or just call the handler with the original schema.
 |          handler: Call into Pydantic's internal JSON schema generation.
 |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
 |              generation fails.
 |              Since this gets called by `BaseModel.model_json_schema` you can override the
 |              `schema_generator` argument to that function to change JSON schema generation globally
 |              for a type.
 |      
 |      Returns:
 |          A JSON schema, as a Python object.
 |  
 |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass
 |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
 |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
 |      be present when this is called.
 |      
 |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
 |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
 |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
 |      
 |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
 |      any kwargs passed to the class definition that aren't used internally by pydantic.
 |      
 |      Args:
 |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
 |              by pydantic.
 |  
 |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  from_orm(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Creates a new instance of the `Model` class with validated data.
 |      
 |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
 |      Default values are respected, but no other validation is performed.
 |      
 |      !!! note
 |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
 |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
 |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
 |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
 |          an error if extra values are passed, but they will be ignored.
 |      
 |      Args:
 |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,
 |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.
 |              Otherwise, the field names from the `values` argument will be used.
 |          values: Trusted or pre-validated data dictionary.
 |      
 |      Returns:
 |          A new instance of the `Model` class with validated data.
 |  
 |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass
 |      Generates a JSON schema for a model class.
 |      
 |      Args:
 |          by_alias: Whether to use attribute aliases or not.
 |          ref_template: The reference template.
 |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
 |              `GenerateJsonSchema` with your desired modifications
 |          mode: The mode in which to generate the schema.
 |      
 |      Returns:
 |          The JSON schema for the given model class.
 |  
 |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str' from pydantic._internal._model_construction.ModelMetaclass
 |      Compute the class name for parametrizations of generic classes.
 |      
 |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
 |      
 |      Args:
 |          params: Tuple of types of the class. Given a generic class
 |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
 |              the value `(str, int)` would be passed to `params`.
 |      
 |      Returns:
 |          String representing the new class where `params` are passed to `cls` as type variables.
 |      
 |      Raises:
 |          TypeError: Raised when trying to generate concrete names for non-generic models.
 |  
 |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None' from pydantic._internal._model_construction.ModelMetaclass
 |      Try to rebuild the pydantic-core schema for the model.
 |      
 |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
 |      the initial attempt to build the schema, and automatic rebuilding fails.
 |      
 |      Args:
 |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
 |          raise_errors: Whether to raise errors, defaults to `True`.
 |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
 |          _types_namespace: The types namespace, defaults to `None`.
 |      
 |      Returns:
 |          Returns `None` if the schema is already "complete" and rebuilding was not required.
 |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
 |  
 |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Validate a pydantic model instance.
 |      
 |      Args:
 |          obj: The object to validate.
 |          strict: Whether to enforce types strictly.
 |          from_attributes: Whether to extract data from object attributes.
 |          context: Additional context to pass to the validator.
 |      
 |      Raises:
 |          ValidationError: If the object could not be validated.
 |      
 |      Returns:
 |          The validated model instance.
 |  
 |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing
 |      
 |      Validate the given JSON data against the Pydantic model.
 |      
 |      Args:
 |          json_data: The JSON data to validate.
 |          strict: Whether to enforce types strictly.
 |          context: Extra variables to pass to the validator.
 |      
 |      Returns:
 |          The validated Pydantic model.
 |      
 |      Raises:
 |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.
 |  
 |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Validate the given object with string data against the Pydantic model.
 |      
 |      Args:
 |          obj: The object containing string data to validate.
 |          strict: Whether to enforce types strictly.
 |          context: Extra variables to pass to the validator.
 |      
 |      Returns:
 |          The validated Pydantic model.
 |  
 |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  parse_obj(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  update_forward_refs(**localns: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  validate(value: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from pydantic.main.BaseModel:
 |  
 |  __fields_set__
 |  
 |  model_computed_fields
 |      Get metadata about the computed fields defined on the model.
 |      
 |      Deprecation warning: you should be getting this information from the model class, not from an instance.
 |      In V3, this property will be removed from the `BaseModel` class.
 |      
 |      Returns:
 |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.
 |  
 |  model_extra
 |      Get extra fields set during validation.
 |      
 |      Returns:
 |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
 |  
 |  model_fields
 |      Get metadata about the fields defined on the model.
 |      
 |      Deprecation warning: you should be getting this information from the model class, not from an instance.
 |      In V3, this property will be removed from the `BaseModel` class.
 |      
 |      Returns:
 |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.
 |  
 |  model_fields_set
 |      Returns the set of fields that have been explicitly set on this model instance.
 |      
 |      Returns:
 |          A set of strings representing the fields that have been set,
 |              i.e. that were not filled from defaults.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pydantic.main.BaseModel:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __pydantic_extra__
 |  
 |  __pydantic_fields_set__
 |  
 |  __pydantic_private__
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from pydantic.main.BaseModel:
 |  
 |  __hash__ = None
 |  
 |  __pydantic_root_model__ = False


=== HumanMessage Documentation ===
Help on class HumanMessage in module langchain_core.messages.human:

class HumanMessage(langchain_core.messages.base.BaseMessage)
 |  HumanMessage(content: Union[str, list[Union[str, dict]]], *, additional_kwargs: dict = <factory>, response_metadata: dict = <factory>, type: Literal['human'] = 'human', name: Optional[str] = None, id: Optional[str] = None, example: bool = False, **kwargs: Any) -> None
 |  
 |  Message from a human.
 |  
 |  HumanMessages are messages that are passed in from a human to the model.
 |  
 |  Example:
 |  
 |      .. code-block:: python
 |  
 |          from langchain_core.messages import HumanMessage, SystemMessage
 |  
 |          messages = [
 |              SystemMessage(
 |                  content="You are a helpful assistant! Your name is Bob."
 |              ),
 |              HumanMessage(
 |                  content="What is your name?"
 |              )
 |          ]
 |  
 |          # Instantiate a chat model and invoke it with the messages
 |          model = ...
 |          print(model.invoke(messages))
 |  
 |  Method resolution order:
 |      HumanMessage
 |      langchain_core.messages.base.BaseMessage
 |      langchain_core.load.serializable.Serializable
 |      pydantic.main.BaseModel
 |      abc.ABC
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, content: Union[str, list[Union[str, dict]]], **kwargs: Any) -> None
 |      Pass in content as positional arg.
 |      
 |      Args:
 |          content: The string contents of the message.
 |          kwargs: Additional fields to pass to the message.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |  
 |  get_lc_namespace() -> list[str] from pydantic._internal._model_construction.ModelMetaclass
 |      Get the namespace of the langchain object.
 |      Default is ["langchain", "schema", "messages"].
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |  
 |  __abstractmethods__ = frozenset()
 |  
 |  __annotations__ = {'example': <class 'bool'>, 'type': typing.Literal['...
 |  
 |  __class_vars__ = set()
 |  
 |  __private_attributes__ = {}
 |  
 |  __pydantic_complete__ = True
 |  
 |  __pydantic_computed_fields__ = {}
 |  
 |  __pydantic_core_schema__ = {'cls': <class 'langchain_core.messages.hum...
 |  
 |  __pydantic_custom_init__ = True
 |  
 |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
 |  
 |  __pydantic_fields__ = {'additional_kwargs': FieldInfo(annotation=dict,...
 |  
 |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
 |  
 |  __pydantic_parent_namespace__ = None
 |  
 |  __pydantic_post_init__ = None
 |  
 |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
 |      Model...
 |  
 |  __pydantic_validator__ = SchemaValidator(title="HumanMessage", validat...
 |  
 |  __signature__ = <Signature (content: Union[str, list[Union[str, ...e, ...
 |  
 |  model_config = {'extra': 'allow'}
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.messages.base.BaseMessage:
 |  
 |  __add__(self, other: 'Any') -> 'ChatPromptTemplate'
 |      Concatenate this message with another message.
 |  
 |  pretty_print(self) -> 'None'
 |  
 |  pretty_repr(self, html: 'bool' = False) -> 'str'
 |      Get a pretty representation of the message.
 |      
 |      Args:
 |          html: Whether to format the message as HTML. If True, the message will be
 |              formatted with HTML tags. Default is False.
 |      
 |      Returns:
 |          A pretty representation of the message.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from langchain_core.messages.base.BaseMessage:
 |  
 |  cast_id_to_str(id_value: 'Any') -> 'Optional[str]' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  is_lc_serializable() -> 'bool' from pydantic._internal._model_construction.ModelMetaclass
 |      Return whether this class is serializable. This is used to determine
 |      whether the class should be included in the langchain schema.
 |      
 |      Returns:
 |          True if the class is serializable, False otherwise.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.load.serializable.Serializable:
 |  
 |  __repr_args__(self) -> Any
 |  
 |  to_json(self) -> Union[langchain_core.load.serializable.SerializedConstructor, langchain_core.load.serializable.SerializedNotImplemented]
 |      Serialize the object to JSON.
 |      
 |      Returns:
 |          A json serializable object or a SerializedNotImplemented object.
 |  
 |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from langchain_core.load.serializable.Serializable:
 |  
 |  lc_id() -> list[str] from pydantic._internal._model_construction.ModelMetaclass
 |      A unique identifier for this class for serialization purposes.
 |      
 |      The unique identifier is a list of strings that describes the path
 |      to the object.
 |      For example, for the class `langchain.llms.openai.OpenAI`, the id is
 |      ["langchain", "llms", "openai", "OpenAI"].
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from langchain_core.load.serializable.Serializable:
 |  
 |  lc_attributes
 |      List of attribute names that should be included in the serialized kwargs.
 |      
 |      These attributes must be accepted by the constructor.
 |      Default is an empty dictionary.
 |  
 |  lc_secrets
 |      A map of constructor argument names to secret ids.
 |      
 |      For example,
 |          {"openai_api_key": "OPENAI_API_KEY"}
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from langchain_core.load.serializable.Serializable:
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pydantic.main.BaseModel:
 |  
 |  __copy__(self) -> 'Self'
 |      Returns a shallow copy of the model.
 |  
 |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
 |      Returns a deep copy of the model.
 |  
 |  __delattr__(self, item: 'str') -> 'Any'
 |      Implement delattr(self, name).
 |  
 |  __eq__(self, other: 'Any') -> 'bool'
 |      Return self==value.
 |  
 |  __getattr__(self, item: 'str') -> 'Any'
 |  
 |  __getstate__(self) -> 'dict[Any, Any]'
 |  
 |  __iter__(self) -> 'TupleGenerator'
 |      So `dict(model)` works.
 |  
 |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]'
 |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
 |  
 |  __replace__(self, **changes: 'Any') -> 'Self'
 |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by
 |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:
 |  
 |  __repr__(self) -> 'str'
 |      Return repr(self).
 |  
 |  __repr_name__(self) -> 'str'
 |      Name of the instance's class, used in __repr__.
 |  
 |  __repr_recursion__(self, object: 'Any') -> 'str'
 |      Returns the string representation of a recursive object.
 |  
 |  __repr_str__(self, join_str: 'str') -> 'str'
 |  
 |  __rich_repr__(self) -> 'RichReprResult'
 |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
 |  
 |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
 |      Implement setattr(self, name, value).
 |  
 |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
 |  
 |  __str__(self) -> 'str'
 |      Return str(self).
 |  
 |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Returns a copy of the model.
 |      
 |      !!! warning "Deprecated"
 |          This method is now deprecated; use `model_copy` instead.
 |      
 |      If you need `include` or `exclude`, use:
 |      
 |      ```python {test="skip" lint="skip"}
 |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
 |      data = {**data, **(update or {})}
 |      copied = self.model_validate(data)
 |      ```
 |      
 |      Args:
 |          include: Optional set or mapping specifying which fields to include in the copied model.
 |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
 |          update: Optional dictionary of field-value pairs to override field values in the copied model.
 |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
 |      
 |      Returns:
 |          A copy of the model with included, excluded and updated fields as specified.
 |  
 |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
 |  
 |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
 |  
 |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy
 |      
 |      Returns a copy of the model.
 |      
 |      Args:
 |          update: Values to change/add in the new model. Note: the data is not validated
 |              before creating the new model. You should trust this data.
 |          deep: Set to `True` to make a deep copy of the model.
 |      
 |      Returns:
 |          New model instance.
 |  
 |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump
 |      
 |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
 |      
 |      Args:
 |          mode: The mode in which `to_python` should run.
 |              If mode is 'json', the output will only contain JSON serializable types.
 |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
 |          include: A set of fields to include in the output.
 |          exclude: A set of fields to exclude from the output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to use the field's alias in the dictionary key if defined.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |      
 |      Returns:
 |          A dictionary representation of the model.
 |  
 |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json
 |      
 |      Generates a JSON representation of the model using Pydantic's `to_json` method.
 |      
 |      Args:
 |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
 |          include: Field(s) to include in the JSON output.
 |          exclude: Field(s) to exclude from the JSON output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to serialize using field aliases.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |      
 |      Returns:
 |          A JSON string representation of the model.
 |  
 |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
 |      Override this method to perform additional initialization after `__init__` and `model_construct`.
 |      This is useful if you want to do some validation that requires the entire model to be initialized.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from pydantic.main.BaseModel:
 |  
 |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema' from pydantic._internal._model_construction.ModelMetaclass
 |      Hook into generating the model's CoreSchema.
 |      
 |      Args:
 |          source: The class we are generating a schema for.
 |              This will generally be the same as the `cls` argument if this is a classmethod.
 |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
 |      
 |      Returns:
 |          A `pydantic-core` `CoreSchema`.
 |  
 |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue' from pydantic._internal._model_construction.ModelMetaclass
 |      Hook into generating the model's JSON schema.
 |      
 |      Args:
 |          core_schema: A `pydantic-core` CoreSchema.
 |              You can ignore this argument and call the handler with a new CoreSchema,
 |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
 |              or just call the handler with the original schema.
 |          handler: Call into Pydantic's internal JSON schema generation.
 |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
 |              generation fails.
 |              Since this gets called by `BaseModel.model_json_schema` you can override the
 |              `schema_generator` argument to that function to change JSON schema generation globally
 |              for a type.
 |      
 |      Returns:
 |          A JSON schema, as a Python object.
 |  
 |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass
 |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
 |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
 |      be present when this is called.
 |      
 |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
 |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
 |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
 |      
 |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
 |      any kwargs passed to the class definition that aren't used internally by pydantic.
 |      
 |      Args:
 |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
 |              by pydantic.
 |  
 |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  from_orm(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Creates a new instance of the `Model` class with validated data.
 |      
 |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
 |      Default values are respected, but no other validation is performed.
 |      
 |      !!! note
 |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
 |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
 |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
 |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
 |          an error if extra values are passed, but they will be ignored.
 |      
 |      Args:
 |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,
 |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.
 |              Otherwise, the field names from the `values` argument will be used.
 |          values: Trusted or pre-validated data dictionary.
 |      
 |      Returns:
 |          A new instance of the `Model` class with validated data.
 |  
 |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass
 |      Generates a JSON schema for a model class.
 |      
 |      Args:
 |          by_alias: Whether to use attribute aliases or not.
 |          ref_template: The reference template.
 |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
 |              `GenerateJsonSchema` with your desired modifications
 |          mode: The mode in which to generate the schema.
 |      
 |      Returns:
 |          The JSON schema for the given model class.
 |  
 |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str' from pydantic._internal._model_construction.ModelMetaclass
 |      Compute the class name for parametrizations of generic classes.
 |      
 |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
 |      
 |      Args:
 |          params: Tuple of types of the class. Given a generic class
 |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
 |              the value `(str, int)` would be passed to `params`.
 |      
 |      Returns:
 |          String representing the new class where `params` are passed to `cls` as type variables.
 |      
 |      Raises:
 |          TypeError: Raised when trying to generate concrete names for non-generic models.
 |  
 |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None' from pydantic._internal._model_construction.ModelMetaclass
 |      Try to rebuild the pydantic-core schema for the model.
 |      
 |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
 |      the initial attempt to build the schema, and automatic rebuilding fails.
 |      
 |      Args:
 |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
 |          raise_errors: Whether to raise errors, defaults to `True`.
 |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
 |          _types_namespace: The types namespace, defaults to `None`.
 |      
 |      Returns:
 |          Returns `None` if the schema is already "complete" and rebuilding was not required.
 |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
 |  
 |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Validate a pydantic model instance.
 |      
 |      Args:
 |          obj: The object to validate.
 |          strict: Whether to enforce types strictly.
 |          from_attributes: Whether to extract data from object attributes.
 |          context: Additional context to pass to the validator.
 |      
 |      Raises:
 |          ValidationError: If the object could not be validated.
 |      
 |      Returns:
 |          The validated model instance.
 |  
 |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing
 |      
 |      Validate the given JSON data against the Pydantic model.
 |      
 |      Args:
 |          json_data: The JSON data to validate.
 |          strict: Whether to enforce types strictly.
 |          context: Extra variables to pass to the validator.
 |      
 |      Returns:
 |          The validated Pydantic model.
 |      
 |      Raises:
 |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.
 |  
 |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Validate the given object with string data against the Pydantic model.
 |      
 |      Args:
 |          obj: The object containing string data to validate.
 |          strict: Whether to enforce types strictly.
 |          context: Extra variables to pass to the validator.
 |      
 |      Returns:
 |          The validated Pydantic model.
 |  
 |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  parse_obj(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  update_forward_refs(**localns: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  validate(value: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from pydantic.main.BaseModel:
 |  
 |  __fields_set__
 |  
 |  model_computed_fields
 |      Get metadata about the computed fields defined on the model.
 |      
 |      Deprecation warning: you should be getting this information from the model class, not from an instance.
 |      In V3, this property will be removed from the `BaseModel` class.
 |      
 |      Returns:
 |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.
 |  
 |  model_extra
 |      Get extra fields set during validation.
 |      
 |      Returns:
 |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
 |  
 |  model_fields
 |      Get metadata about the fields defined on the model.
 |      
 |      Deprecation warning: you should be getting this information from the model class, not from an instance.
 |      In V3, this property will be removed from the `BaseModel` class.
 |      
 |      Returns:
 |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.
 |  
 |  model_fields_set
 |      Returns the set of fields that have been explicitly set on this model instance.
 |      
 |      Returns:
 |          A set of strings representing the fields that have been set,
 |              i.e. that were not filled from defaults.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pydantic.main.BaseModel:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __pydantic_extra__
 |  
 |  __pydantic_fields_set__
 |  
 |  __pydantic_private__
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from pydantic.main.BaseModel:
 |  
 |  __hash__ = None
 |  
 |  __pydantic_root_model__ = False


=== AIMessage Documentation ===
Help on class AIMessage in module langchain_core.messages.ai:

class AIMessage(langchain_core.messages.base.BaseMessage)
 |  AIMessage(content: Union[str, list[Union[str, dict]]], *, additional_kwargs: dict = <factory>, response_metadata: dict = <factory>, type: Literal['ai'] = 'ai', name: Optional[str] = None, id: Optional[str] = None, example: bool = False, tool_calls: list[langchain_core.messages.tool.ToolCall] = [], invalid_tool_calls: list[langchain_core.messages.tool.InvalidToolCall] = [], usage_metadata: Optional[langchain_core.messages.ai.UsageMetadata] = None, **kwargs: Any) -> None
 |  
 |  Message from an AI.
 |  
 |  AIMessage is returned from a chat model as a response to a prompt.
 |  
 |  This message represents the output of the model and consists of both
 |  the raw output as returned by the model together standardized fields
 |  (e.g., tool calls, usage metadata) added by the LangChain framework.
 |  
 |  Method resolution order:
 |      AIMessage
 |      langchain_core.messages.base.BaseMessage
 |      langchain_core.load.serializable.Serializable
 |      pydantic.main.BaseModel
 |      abc.ABC
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, content: Union[str, list[Union[str, dict]]], **kwargs: Any) -> None
 |      Pass in content as positional arg.
 |      
 |      Args:
 |          content: The content of the message.
 |          kwargs: Additional arguments to pass to the parent class.
 |  
 |  pretty_repr(self, html: bool = False) -> str
 |      Return a pretty representation of the message.
 |      
 |      Args:
 |          html: Whether to return an HTML-formatted string.
 |               Defaults to False.
 |      
 |      Returns:
 |          A pretty representation of the message.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |  
 |  get_lc_namespace() -> list[str] from pydantic._internal._model_construction.ModelMetaclass
 |      Get the namespace of the langchain object.
 |      
 |      Returns:
 |          The namespace of the langchain object.
 |          Defaults to ["langchain", "schema", "messages"].
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties defined here:
 |  
 |  lc_attributes
 |      Attrs to be serialized even if they are derived from other init args.
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |  
 |  __abstractmethods__ = frozenset()
 |  
 |  __annotations__ = {'example': <class 'bool'>, 'invalid_tool_calls': li...
 |  
 |  __class_vars__ = set()
 |  
 |  __private_attributes__ = {}
 |  
 |  __pydantic_complete__ = True
 |  
 |  __pydantic_computed_fields__ = {}
 |  
 |  __pydantic_core_schema__ = {'cls': <class 'langchain_core.messages.ai....
 |  
 |  __pydantic_custom_init__ = True
 |  
 |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
 |  
 |  __pydantic_fields__ = {'additional_kwargs': FieldInfo(annotation=dict,...
 |  
 |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
 |  
 |  __pydantic_parent_namespace__ = None
 |  
 |  __pydantic_post_init__ = None
 |  
 |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
 |      Model...
 |  
 |  __pydantic_validator__ = SchemaValidator(title="AIMessage", validator=...
 |  
 |  __signature__ = <Signature (content: Union[str, list[Union[str, ...ai....
 |  
 |  model_config = {'extra': 'allow'}
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.messages.base.BaseMessage:
 |  
 |  __add__(self, other: 'Any') -> 'ChatPromptTemplate'
 |      Concatenate this message with another message.
 |  
 |  pretty_print(self) -> 'None'
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from langchain_core.messages.base.BaseMessage:
 |  
 |  cast_id_to_str(id_value: 'Any') -> 'Optional[str]' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  is_lc_serializable() -> 'bool' from pydantic._internal._model_construction.ModelMetaclass
 |      Return whether this class is serializable. This is used to determine
 |      whether the class should be included in the langchain schema.
 |      
 |      Returns:
 |          True if the class is serializable, False otherwise.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from langchain_core.load.serializable.Serializable:
 |  
 |  __repr_args__(self) -> Any
 |  
 |  to_json(self) -> Union[langchain_core.load.serializable.SerializedConstructor, langchain_core.load.serializable.SerializedNotImplemented]
 |      Serialize the object to JSON.
 |      
 |      Returns:
 |          A json serializable object or a SerializedNotImplemented object.
 |  
 |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from langchain_core.load.serializable.Serializable:
 |  
 |  lc_id() -> list[str] from pydantic._internal._model_construction.ModelMetaclass
 |      A unique identifier for this class for serialization purposes.
 |      
 |      The unique identifier is a list of strings that describes the path
 |      to the object.
 |      For example, for the class `langchain.llms.openai.OpenAI`, the id is
 |      ["langchain", "llms", "openai", "OpenAI"].
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from langchain_core.load.serializable.Serializable:
 |  
 |  lc_secrets
 |      A map of constructor argument names to secret ids.
 |      
 |      For example,
 |          {"openai_api_key": "OPENAI_API_KEY"}
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from langchain_core.load.serializable.Serializable:
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pydantic.main.BaseModel:
 |  
 |  __copy__(self) -> 'Self'
 |      Returns a shallow copy of the model.
 |  
 |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
 |      Returns a deep copy of the model.
 |  
 |  __delattr__(self, item: 'str') -> 'Any'
 |      Implement delattr(self, name).
 |  
 |  __eq__(self, other: 'Any') -> 'bool'
 |      Return self==value.
 |  
 |  __getattr__(self, item: 'str') -> 'Any'
 |  
 |  __getstate__(self) -> 'dict[Any, Any]'
 |  
 |  __iter__(self) -> 'TupleGenerator'
 |      So `dict(model)` works.
 |  
 |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]'
 |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
 |  
 |  __replace__(self, **changes: 'Any') -> 'Self'
 |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by
 |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:
 |  
 |  __repr__(self) -> 'str'
 |      Return repr(self).
 |  
 |  __repr_name__(self) -> 'str'
 |      Name of the instance's class, used in __repr__.
 |  
 |  __repr_recursion__(self, object: 'Any') -> 'str'
 |      Returns the string representation of a recursive object.
 |  
 |  __repr_str__(self, join_str: 'str') -> 'str'
 |  
 |  __rich_repr__(self) -> 'RichReprResult'
 |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
 |  
 |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
 |      Implement setattr(self, name, value).
 |  
 |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
 |  
 |  __str__(self) -> 'str'
 |      Return str(self).
 |  
 |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Returns a copy of the model.
 |      
 |      !!! warning "Deprecated"
 |          This method is now deprecated; use `model_copy` instead.
 |      
 |      If you need `include` or `exclude`, use:
 |      
 |      ```python {test="skip" lint="skip"}
 |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
 |      data = {**data, **(update or {})}
 |      copied = self.model_validate(data)
 |      ```
 |      
 |      Args:
 |          include: Optional set or mapping specifying which fields to include in the copied model.
 |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
 |          update: Optional dictionary of field-value pairs to override field values in the copied model.
 |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
 |      
 |      Returns:
 |          A copy of the model with included, excluded and updated fields as specified.
 |  
 |  dict(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
 |  
 |  json(self, *, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
 |  
 |  model_copy(self, *, update: 'Mapping[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy
 |      
 |      Returns a copy of the model.
 |      
 |      Args:
 |          update: Values to change/add in the new model. Note: the data is not validated
 |              before creating the new model. You should trust this data.
 |          deep: Set to `True` to make a deep copy of the model.
 |      
 |      Returns:
 |          New model instance.
 |  
 |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump
 |      
 |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
 |      
 |      Args:
 |          mode: The mode in which `to_python` should run.
 |              If mode is 'json', the output will only contain JSON serializable types.
 |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
 |          include: A set of fields to include in the output.
 |          exclude: A set of fields to exclude from the output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to use the field's alias in the dictionary key if defined.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |      
 |      Returns:
 |          A dictionary representation of the model.
 |  
 |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx | None' = None, exclude: 'IncEx | None' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json
 |      
 |      Generates a JSON representation of the model using Pydantic's `to_json` method.
 |      
 |      Args:
 |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
 |          include: Field(s) to include in the JSON output.
 |          exclude: Field(s) to exclude from the JSON output.
 |          context: Additional context to pass to the serializer.
 |          by_alias: Whether to serialize using field aliases.
 |          exclude_unset: Whether to exclude fields that have not been explicitly set.
 |          exclude_defaults: Whether to exclude fields that are set to their default value.
 |          exclude_none: Whether to exclude fields that have a value of `None`.
 |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
 |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
 |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
 |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
 |      
 |      Returns:
 |          A JSON string representation of the model.
 |  
 |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
 |      Override this method to perform additional initialization after `__init__` and `model_construct`.
 |      This is useful if you want to do some validation that requires the entire model to be initialized.
 |  
 |  ----------------------------------------------------------------------
 |  Class methods inherited from pydantic.main.BaseModel:
 |  
 |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema' from pydantic._internal._model_construction.ModelMetaclass
 |      Hook into generating the model's CoreSchema.
 |      
 |      Args:
 |          source: The class we are generating a schema for.
 |              This will generally be the same as the `cls` argument if this is a classmethod.
 |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
 |      
 |      Returns:
 |          A `pydantic-core` `CoreSchema`.
 |  
 |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue' from pydantic._internal._model_construction.ModelMetaclass
 |      Hook into generating the model's JSON schema.
 |      
 |      Args:
 |          core_schema: A `pydantic-core` CoreSchema.
 |              You can ignore this argument and call the handler with a new CoreSchema,
 |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
 |              or just call the handler with the original schema.
 |          handler: Call into Pydantic's internal JSON schema generation.
 |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
 |              generation fails.
 |              Since this gets called by `BaseModel.model_json_schema` you can override the
 |              `schema_generator` argument to that function to change JSON schema generation globally
 |              for a type.
 |      
 |      Returns:
 |          A JSON schema, as a Python object.
 |  
 |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass
 |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
 |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
 |      be present when this is called.
 |      
 |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
 |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
 |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
 |      
 |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
 |      any kwargs passed to the class definition that aren't used internally by pydantic.
 |      
 |      Args:
 |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
 |              by pydantic.
 |  
 |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  from_orm(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Creates a new instance of the `Model` class with validated data.
 |      
 |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
 |      Default values are respected, but no other validation is performed.
 |      
 |      !!! note
 |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
 |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
 |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
 |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
 |          an error if extra values are passed, but they will be ignored.
 |      
 |      Args:
 |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,
 |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.
 |              Otherwise, the field names from the `values` argument will be used.
 |          values: Trusted or pre-validated data dictionary.
 |      
 |      Returns:
 |          A new instance of the `Model` class with validated data.
 |  
 |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass
 |      Generates a JSON schema for a model class.
 |      
 |      Args:
 |          by_alias: Whether to use attribute aliases or not.
 |          ref_template: The reference template.
 |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
 |              `GenerateJsonSchema` with your desired modifications
 |          mode: The mode in which to generate the schema.
 |      
 |      Returns:
 |          The JSON schema for the given model class.
 |  
 |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str' from pydantic._internal._model_construction.ModelMetaclass
 |      Compute the class name for parametrizations of generic classes.
 |      
 |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
 |      
 |      Args:
 |          params: Tuple of types of the class. Given a generic class
 |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
 |              the value `(str, int)` would be passed to `params`.
 |      
 |      Returns:
 |          String representing the new class where `params` are passed to `cls` as type variables.
 |      
 |      Raises:
 |          TypeError: Raised when trying to generate concrete names for non-generic models.
 |  
 |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'MappingNamespace | None' = None) -> 'bool | None' from pydantic._internal._model_construction.ModelMetaclass
 |      Try to rebuild the pydantic-core schema for the model.
 |      
 |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
 |      the initial attempt to build the schema, and automatic rebuilding fails.
 |      
 |      Args:
 |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
 |          raise_errors: Whether to raise errors, defaults to `True`.
 |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
 |          _types_namespace: The types namespace, defaults to `None`.
 |      
 |      Returns:
 |          Returns `None` if the schema is already "complete" and rebuilding was not required.
 |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
 |  
 |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Validate a pydantic model instance.
 |      
 |      Args:
 |          obj: The object to validate.
 |          strict: Whether to enforce types strictly.
 |          from_attributes: Whether to extract data from object attributes.
 |          context: Additional context to pass to the validator.
 |      
 |      Raises:
 |          ValidationError: If the object could not be validated.
 |      
 |      Returns:
 |          The validated model instance.
 |  
 |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing
 |      
 |      Validate the given JSON data against the Pydantic model.
 |      
 |      Args:
 |          json_data: The JSON data to validate.
 |          strict: Whether to enforce types strictly.
 |          context: Extra variables to pass to the validator.
 |      
 |      Returns:
 |          The validated Pydantic model.
 |      
 |      Raises:
 |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.
 |  
 |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |      Validate the given object with string data against the Pydantic model.
 |      
 |      Args:
 |          obj: The object containing string data to validate.
 |          strict: Whether to enforce types strictly.
 |          context: Extra variables to pass to the validator.
 |      
 |      Returns:
 |          The validated Pydantic model.
 |  
 |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  parse_obj(obj: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  update_forward_refs(**localns: 'Any') -> 'None' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  validate(value: 'Any') -> 'Self' from pydantic._internal._model_construction.ModelMetaclass
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from pydantic.main.BaseModel:
 |  
 |  __fields_set__
 |  
 |  model_computed_fields
 |      Get metadata about the computed fields defined on the model.
 |      
 |      Deprecation warning: you should be getting this information from the model class, not from an instance.
 |      In V3, this property will be removed from the `BaseModel` class.
 |      
 |      Returns:
 |          A mapping of computed field names to [`ComputedFieldInfo`][pydantic.fields.ComputedFieldInfo] objects.
 |  
 |  model_extra
 |      Get extra fields set during validation.
 |      
 |      Returns:
 |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
 |  
 |  model_fields
 |      Get metadata about the fields defined on the model.
 |      
 |      Deprecation warning: you should be getting this information from the model class, not from an instance.
 |      In V3, this property will be removed from the `BaseModel` class.
 |      
 |      Returns:
 |          A mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.
 |  
 |  model_fields_set
 |      Returns the set of fields that have been explicitly set on this model instance.
 |      
 |      Returns:
 |          A set of strings representing the fields that have been set,
 |              i.e. that were not filled from defaults.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pydantic.main.BaseModel:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __pydantic_extra__
 |  
 |  __pydantic_fields_set__
 |  
 |  __pydantic_private__
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from pydantic.main.BaseModel:
 |  
 |  __hash__ = None
 |  
 |  __pydantic_root_model__ = False

